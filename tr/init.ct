# traction

commonly used getters (and setters?) for centraxx db.

``//__init__.py: #py
``import``
``const``

``_checkverbose``
``floatornull``
``get_ids``
``isnumber``
``isidentifier``

``idable_csv``
``finding_csv``

class traction:
    ``init``

    ``sample``
    ``_get_parents``
    ``_get_childs``
    ``patient``
    ``trial``
    ``finding``
    ``method``
    ``user``
    ``catalogentry``
    ``usageentry``
    ``name``
    
    ``sidc``
    ``pidc``

    ``_selectstr``
    ``_joinstr``
    ``_append_idc_select``
    ``_append_idc_join``
    ``_where``
    ``_wherebuild``
    ``_sqlinplaceholder``
    ``_whereparam``
    ``_wherelike``
    ``_wherelikes``
    ``_top``
    ``_order_by``    
    ``_idcinit``
    ``_make_rec``
    ``_sampleidcs``
    ``_patientidcs``
    ``_concrete_idcs``
    ``_concrete_idcs_dict``    
    
    ``_fill_in_primary``

    ``_bcp``
    ``_bcp_table``
    ``_bcp_clean``
    ``_tbl_exists``
``

at the package level are a series of constants that can be used in
function calls, e.g. sample(..., verbose=[tr.parentid,
tr.locationpath]).

maybe keep the names in lowercase so that they are the same as the
keys in the returned json?

``/const: #py
address = "address"
appointment = "appointment"
category = "category" # MASTER, ALIQUOTGROUP, DERIVED. dtype in db.
concentration = "concentration"
cxxkitid = "cxxkitid"
creationdate = "creationdate" 
derivaldate = "derivaldate" # aufteilungsdatum / date of distribution
email = "email"
initialamount = "initialamount"
initialunit = "initialunit"
first_repositiondate = "first_repositiondate" # datum der ersten einlagerung / date of first storage (not in fhir). is identical to derivaldate. first_repositiondate in db.
method = "method"
kitid = "kitid"
lastlogin = "lastlogin"
login = "login"
locationname = "locationname"
locationpath = "locationpath"
orga = "orga"
parentid = "parentid"
parentoid = "parentoid"
patientid = "patientid"
project = "project"
receiptdate = "receiptdate" # eingangsdatum / date of receipt. receiptdate in db.
receptacle = "receptacle"
repositiondate = "repositiondate" # datum der letzten einlagerung / most recent storage date. 
restamount = "restamount"
restunit = "restunit"
sampleid = "sampleid"
sampleoid = "sampleoid"
sampletype = "sampletype"
samplingdate = "samplingdate" # entnahmedatum / extraction date.
secondprocessing = "secondprocessing"
secondprocessingdate = "secondprocessingdate"
stockprocessing = "stockprocessing"
stockprocessingdate = "stockprocessingdate"
trial = "trial"
type = "type" # sampletype (EDTA, stool etc) in db.
username = "username"
values = "values"
xposition = "xposition"
yposition = "yposition"
``

__init__ takes the db target either as string or dbcq object.

``/init: #py
    def __init__(self, target):
        ``.``
``

get the settings. if the settings file is missing, cnf creates it and
asks the user to edit it.

``
        self.settings = cnf.makeload(path=".traction/settings.yaml", root=cnf.home, fmt="yaml", make=cnftemplate)        
``

if no settings, do nothing. 

``
        if self.settings == None:
            raise Exception("no settings.")
            return
``

either pass a string argument to dbcq or use dbcq instance directly.

`` #py
        if isinstance(target, str):
            self.db = dbcq(target)
        elif isinstance(target, dbcq): 
            self.db = target
        else:
            raise Exception("target needs to be string or dbcq instance")
``

cache the id containers' oids and kinds by code.

``
        self._idcinit()
        #print(f"_idcoids: {self._idcoids}")
``

make a join-dict, jd, that holds joins from table a to table b.

init jd here, cause it needs to reference self at one point for joining in an idc_ table.

``
        self.jd = {
            ``jd sample_to``
            ,
            ``jd patient_to``
            ,
            ``jd participant_to``
        }
``

set the display name caches.

``
        self.names_labval = None
        self.names_catalogentry = None
        self.names_usageentry = None
``

import dbcq and cnf.

``/import: #py
from dbcq import *
import cnf
``

add a variable that holds the conf template.

``/const
cnftemplate = """
# settings for traction.

# sampleid sets the idcontainertype code that is used when searching for sampleid.
# put in a code per db target.
sampleid: 
  <db target>: <an idcontainertype code, e.g. SAMPLEID>
# patientid sets the idcontainertype code that is used when searching for patientid.
# put in a code per db target.
patientid: 
  <db target>: <an idcontainertype code, e.g. LIMSPSN>

# idc holds additional idcontainertype codes that will be queryable as command line flags.
idc:
 - <an idcontainertype code>
 - <another idcontainertype code>
"""
``

sample gets sample(s) and returns them as a list of Sample instances.

pass sampleids and other values to filter for as lists of strings,
e.g. `sampleids=["a", "b", "c"]`.

use the idc param to filter for idcontainer lists by passing a dict of
lists keyed by idcontainer code, e.g. `idc={"extsampleid": ["a", "b", "c"]}`.

put info that should be joined into the result into the verbose array,
e.g.  `verbose=[tr.locationpath]`. to join in everything, say
`verbose_all=True`. this is slower than non-verbose.

pass dates as a tuple of from and to datetime, e.g. `samplingdates=(datefrom, None)`.

to check via like as opposed to exact, put the respective fields into
the like array, e.g. `like=[tr.locationpath]`.

``/sample: #py
    def sample(self, sampleids:list=None, oids:list=None, idc=None, patientids:list=None, pidc:str=None, parentids:list=None, parentoids:list=None, locationpaths:list=None, trials:list=None, kitids:list=None, cxxkitids:list=None, categories:list=None, types:list=None, orgas:list=None, samplingdates=None, receiptdates=None, derivaldates=None, first_repositiondates=None, repositiondates=None, stockprocessingdates=None, secondprocessingdates=None, files:dict=None, verbose:list=None, verbose_all=False, primaryref:bool=False, incl_parents:bool=False, incl_childs:bool=False, incl_tree:bool=False, like:list=None, missing=False, order_by=None, top=None, print_query:bool=False, raw:bool=False):
        ``.``
``

init arrays.  don't set them as mutable default parameters
(e.g. verbose=[]), cause they would then retain their values across
method calls. see
https://www.geeksforgeeks.org/python/use-mutable-default-value-as-an-argument-in-python/

``
        if verbose is None:
            verbose = []
        if like is None:
            like = []
        if files is None:
            files = {}
``

these are all possible verbose options (verbose-all-array).

let sampleid be the first element in vaa so it gets joined in first
for subsequent joins that depend on it.

`` #py
        # print("try:" + tr.sampleid)
        vaa = [cxxkitid, kitid, locationname, locationpath, orga, parentid, 
               project, receptacle, sampletype,
               secondprocessing, stockprocessing, trial]
``

append the idcs for patient and sample to the vaa array.  

``
        vaa.extend(self._patientidcs(pidc))
        vaa.extend(self._sampleidcs())                
``

always join in the sampleid for now, again, as the first array element
for subsequent joins that might need it.

`` #py
        if not self.sidc() in verbose:
            verbose.insert(0, self.sidc())
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        files = self._concrete_idcs_dict(files, pidc=pidc)
        #print("files:")
        #print(files)
``

load the data from files into tables. see the method comment for _bcp
why we're doing this.

``
        filetables = self._bcp(files)
        #filetables = { "idc_SAMPLEID": "trac.sampleids" }
        #print("filetables:")
        #print(filetables)
``        

put the keys for the given arguments into the verbose array, so that
they land in the join, so that the wherestring can access the
joined-in fields.

`` #py
        if trials:
            verbose.append(trial)
        if locationpaths:
            verbose.append(locationpath)
        if kitids:
            verbose.append(kitid)
        if cxxkitid:
            verbose.append(cxxkitid)
        if parentids:
            verbose.append(parentid)
        if orgas:
            verbose.append(orga)
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
``

make sure that the verbose array only contains keys from the verbose-all-array.

``
        if not _checkverbose(verbose, vaa): 
            return None # throw error?
``

after the verbose array was filled walk the sample tree if needed.

there are two cases where we walk the sample tree:

(a) including other samples.

if the sample's parents, children or it's whole tree should be
included in the result, first run this call, take the sample oids
returned, then add the oids of the parents / childs / tree samples (in
order from root to leaf), and then run the query with its verboses for
all the sample oids.

(b) referencing the primary sample for each derived sample.

if each derived sample should reference its primary, also
run the call, and then fill in the primary field for each sample.

at first it was thought to do the primary referencing via verbose, but
then each verbose all call would include the primary references, which
might slow it down?

check if we walk the sample tree.

``
        if incl_parents or incl_childs or incl_tree or primaryref:
            ``incl``
``

we fire the call with all the arguments except incl_*, and raw.

we pass only verbose if we add primary references, cause then we only
run the call once. if we include tree samples later we don't pass
verbose, cause we eventually run the call again for all tree samples,
passing verbose here would slow it down.

it shouldn't make a difference to pass verbose_all for primary, cause
verbose should be filled in any case.

``/sample/incl:
            verbosepass = []
            if primaryref:
                verbosepass = verbose
``

fire the call, then add to the result.

``
            res = self.sample(sampleids=sampleids, idc=idc, parentids=parentids, parentoids=parentoids, patientids=patientids, pidc=pidc, trials=trials, locationpaths=locationpaths, kitids=kitids, cxxkitids=cxxkitids, categories=categories, samplingdates=samplingdates, receiptdates=receiptdates, derivaldates=derivaldates, first_repositiondates=first_repositiondates, repositiondates=repositiondates, stockprocessingdates=stockprocessingdates, secondprocessingdates=secondprocessingdates, verbose=verbosepass, verbose_all=False, like=like, missing=missing, order_by=order_by, top=top, print_query=print_query)
``

proceed differently if primary info should be added or if samples from
the tree should be included.

``
            if primaryref:
                for sample in res:
                    self._fill_in_primary(sample)
                return res
``

when including samples from the tree, take all the sample oids.

use oids to support aliquotgroups.

``/sample/incl
            
            s_oids = get_ids(res, "oid")
``

withincl holds all the sampleids that eventually get queried.

``
            withincl = []
``

now put in the sample oids of parents, childs or the whole tree.

``
            for s_oid in s_oids:
               if incl_parents:
                   ``parents``
               if incl_childs:
                   ``childs``
               if incl_tree:
                   ``tree``
``

if the parent sampleids should be included, get them from root to
leaf. collect them into the pids list.

``/sample/incl/parents:
                   p_oids = []
                   self._get_parents(s_oid, p_oids)
``

put the parent oids in, followed by our sample oid.

``
                   withincl.extend(p_oids)
                   withincl.append(s_oid)
``

if the child oids should be included, get them from sample to leaf.

``/sample/incl/childs:
                  c_oids = []
                  self._get_childs(s_oid, c_oids)
``

put the child oids in, preceeded by our sample oid.

``
                  withincl.append(s_oid)
                  withincl.extend(c_oids)
``

if the whole tree should be included, get the root, and include all
children from there.

``/sample/incl/tree:
                  p_oids = []
                  self._get_parents(s_oid, p_oids)
                  if len(p_oids) > 0:
                      root = p_oids[0]
                  else:
                      root = s_oid
``

get the child oids from root.

``
                  c_oids = []
                  self._get_childs(root, c_oids)
``

append the root oid, then the child oids.

``
                  withincl.append(root)
                  withincl.extend(c_oids)
``

after filling withincl, filter out recurring sampleids. keep each id
where it first appeared in the array to preserve tree dependencies.


``/sample/incl
            withincl = list(dict.fromkeys(withincl))
``

using dict.fromkeys here depends on python dicts preserving insertion order
since python 3.7.

now run the query for all the sampleids with the verboses. the
verboses should contain all the query parameters from the original
call. in the call here we don't pass the query parameters from the
original call, cause we used them already to get the sampleids, and
here they could filter out parent/child/tree samples we'd like to keep.

``
            return self.sample(oids=withincl, verbose=verbose, print_query=print_query, raw=raw) # todo pass verbose_all?
``

put the sampleids and patientids into idc, to handle them as just
another idcontainer for joining and in where.

``/sample
        # todo check that self.sidc() is not in idc
        if idc is None:
           idc = {}
        if sampleids is not None:
           idc[self.sidc()] = sampleids
        if patientids is not None:
           idc[self.pidc(pidc)] = patientids
``

jselect holds statements for optional joins by key.

rename the field of the main sample idcontainer to sampleid.

`` #py
        jselects = {
            self.sidc(): [f"idc_{self.sidc()}.psn as '{sampleid}'"],
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],                   
            cxxkitid: [f"samplekit.cxxkitid as '{cxxkitid}'"],
            #sampleid: [f"sidc.psn as '{sampleid}'"],
            parentid: [f"parentidc.psn as '{parentid}'"],
            kitid: [f"samplekit.kitid as '{kitid}'"],
            locationname: [f"samplelocation.locationid as '{locationname}'"], 
            locationpath: [f"samplelocation.locationpath as '{locationpath}'"],
            sampletype: [f"sampletype.code as '{sampletype}'"],
            stockprocessing: [f"stockprocessing.code as '{stockprocessing}'"],
            secondprocessing: [f"secondprocessing.code as '{secondprocessing}'"],
            project: [f"project.code as '{project}'"],
            #patientid: [f"patidc.psn as '{patientid}'"],
            receptacle: [f"receptable.code as '{receptacle}'"],
            orga: [f"organisationunit.code as '{orga}'"],
            trial: [f"flexistudy.code as '{trial}'"],
        }
``

lselects holds the local selects for this table, for field renames.

put sample.* first, that it doesn't overwrite field of the renames?

``
        lselects = [
          f"sample.amountrest as {restamount}",
          f"sample.appointmentnumber as {appointment}",
          f"sample.dtype as {category}",
          f"sample.oid as {sampleoid}",
          f"sample.parent as {parentoid}",
          "sample.*"
        ]
``

the join statements for optional joins by key. if the same join is
needed for two different keys (e.g. locationname and locationpath),
filter them out later.

pull the values from the join dict, jd.

`` #py
        joins = {
            cxxkitid: self.jd["sample_to_samplekit"],
            parentid: self.jd["sample_to_parentid"],
            kitid: self.jd["sample_to_samplekit"],
            locationname: self.jd["sample_to_samplelocation"],
            locationpath: self.jd["sample_to_samplelocation"],
            sampletype: self.jd["sample_to_sampletype"],
            stockprocessing: self.jd["sample_to_stockprocessing"],
            secondprocessing: self.jd["sample_to_secondprocessing"],
            project: self.jd["sample_to_project"],
            receptacle: self.jd["sample_to_receptacle"],
            orga: self.jd["sample_to_orga"],
            trial: self.jd["sample_to_trial"]
        }
``

for any patient idc, join in patientcontainer, which is needed by
_append_idc_joins.

``
        for pidc in self._patientidcs(pidc):
            joins[pidc] = self.jd["sample_to_patient"]
``

put together the select string and join string for the query.

`` #py
        selectstr = self._selectstr(jselects, verbose, lselects, idc)  
        joinstr = self._joinstr(joins, verbose, idc, pidc=pidc)  
``

get the where string.

`` #py
        (wherestr, whereargs) = self._where(idc=idc, sampleoids=oids, parentids=parentids, parentoids=parentoids, trials=trials, locationpaths=locationpaths, kitids=kitids, cxxkitids=cxxkitids, categories=categories, types=types, orgas=orgas, samplingdates=samplingdates, receiptdates=receiptdates, derivaldates=derivaldates, first_repositiondates=first_repositiondates, repositiondates=repositiondates, stockprocessingdates=stockprocessingdates, secondprocessingdates=secondprocessingdates, filetables=filetables, verbose=verbose, like=like) 
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query, get the result and return it.

`` #py
        query = f"select {topstr} {selectstr} from centraxx_sample sample \n{joinstr}"
        if wherestr.strip() != "":
            query += f"\nwhere {wherestr}"
        if order_by is not None:
            query += " " + self._order_by(order_by)
            
        if print_query:
           print(query)
           print(whereargs)

        res = self.db.qfad(query, whereargs)
``

remove the temporary tables holding bcp data.

``
        self._bcp_clean(filetables)
``

if raw is wished return the raw result.

``
        if raw:
            return res
``

the first implementation tried to take the tablenames/colums as keys
for the returned json fields, but that doesn't quite work for
patientpsn, where the key would be just 'idcontainer.psn'. so for now
joined-in fields are renamed to 'sampleid', 'patientid',
'parentid' etc. // todo still true?

turn the result to samples.

``
        sarr = []
        for r in res:
            ``.``
``

collect the sample's ids.

``
            ids = []
            #if dig(r, sampleid) is not None:
            #    ids.append(Identifier(id=dig(r, sampleid), code=self.sidc()))
            for idc in self._sampleidcs():
                #print("idc:" + idc)
                #print("r:" + str(r))
                if idc.lower() in r and r[idc.lower()] is not None:
                    ids.append( Identifier(id=dig(r, idc.lower()), code=idc.upper()) )
``

include the oid.

``
            ids.append( Identifier(id=int(dig(r, sampleoid)), code="oid") ) # todo rename sampleoid?
``

reference the parent as an Idable to be able to include both oid and
sampleid. the oid is needed for aliquotgroups that don't come with an
idcontainer.

``
            pids = []
            if r[parentoid] is not None:
                pids.append(Identifier(id=int(r[parentoid]), code="oid"))
            if dig(r, parentid) is not None:
                pids.append(Identifier(id=dig(r, parentid), code=self.sidc()))
            parent = None
            if len(pids) > 0:
                parent = Idable(ids=pids, mainidc=self.sidc())
``

also reference the patient as Idable.

``
            patids = []
            if dig(r, patientid) is not None:   # todo include patient oid?
                patids.append(Identifier(id=dig(r, patientid), code=self.pidc(pidc)))
            patient = None
            if len(patids) > 0:
                patient = Idable(ids=patids, mainidc=self.pidc(pidc))
``

build the sample.

``
            s = Sample(
                appointment=dig(r, appointment),
                category=dig(r, category),
                samplingdate=dig(r, samplingdate),
                concentration=dig(r, concentration),
                cxxkitid=dig(r, cxxkitid),
                creationdate=dig(r, creationdate),
                derivaldate=dig(r, derivaldate),
                ids=Idable(ids=ids, mainidc=self.sidc()),
                initialamount=Amount(floatornull(dig(r, initialamount)), dig(r, initialunit)), # apparently the cast to float is explicitly needed
                kitid=dig(r, kitid),
                locationpath=dig(r, locationpath),
                locationname=dig(r, locationname),
                orga=dig(r, orga),
                parent=parent,
                patient=patient,
                project=dig(r, project),
                receiptdate=dig(r, receiptdate),
                receptacle=dig(r, receptacle),
                repositiondate=dig(r, repositiondate),
                restamount=Amount(floatornull(dig(r, restamount)), dig(r, restunit)),
                secondprocessing=dig(r, secondprocessing),
                secondprocessingdate=dig(r, secondprocessingdate),
                stockprocessing=dig(r, stockprocessing),
                stockprocessingdate=dig(r, stockprocessingdate),
                trial=dig(r, trial),
                type=dig(r, sampletype),
                xposition=dig(r, xposition), 
                yposition=dig(r, yposition)
            )
            sarr.append(s)
``

buffer each fetch to r with dig, for keys that are not in r.

return.

``/sample
        return sarr
``

import.

``/import
from datetime import datetime
from dip import dig, dis
from tram import Sample, Idable, Amount, Identifier
``

the joindict entries that sample needs.

``/init/jd sample_to:
            "sample_to_samplekit": [f"left join centraxx_samplekititem as samplekititem on samplekititem.tubebarcode = idc_{self.sidc()}.psn", "left join centraxx_samplekit as samplekit on samplekit.oid = samplekititem.samplekit"],
            "sample_to_parentid": [f"left join centraxx_sampleidcontainer parentidc on parentidc.sample = sample.parent and parentidc.idcontainertype={self._idcoid[self.sidc()]}"],
            "sample_to_samplelocation": ["left join centraxx_samplelocation samplelocation on samplelocation.oid = sample.samplelocation"],
            "sample_to_sampletype": ["left join centraxx_sampletype as sampletype on sampletype.oid = sample.sampletype"],
            "sample_to_stockprocessing": ["left join centraxx_stockprocessing as stockprocessing on sample.stockprocessing = stockprocessing.oid"],
            "sample_to_secondprocessing": ["left join centraxx_stockprocessing as secondprocessing on sample.secondprocessing = secondprocessing.oid"],
            "sample_to_project": ["left join centraxx_project as project on sample.project = project.oid"],
            "sample_to_patient": ["left join centraxx_patientcontainer as patientcontainer on sample.patientcontainer = patientcontainer.oid"],
            "sample_to_receptacle": ["left join centraxx_samplereceptable as receptable on sample.receptable = receptable.oid"], # receptable seems to be a typo in the table naming
            "sample_to_orga": ["left join centraxx_organisationunit as organisationunit on sample.orgunit = organisationunit.oid"],
            "sample_to_trial": ["left join centraxx_flexistudy as flexistudy on sample.flexistudy = flexistudy.oid"]
``

_get_parents collects the parent sample oids of a sample in the `out`
list, in order from root to leaf. take oids to include aliquotgroups,
they don't necessarily have an idcontainer attached to them.

``/_get_parents:
    def _get_parents(self, oid, out):
        ``.``
``

get the parent oid. query directly for performance (sample() would
join in the sampleid idcontainer by default).

``
        res = self.db.qfad("select parent from centraxx_sample where oid = ?", oid)
        pid = dig(res[0], "parent")
``

insert the parent at the front of the out array, to keep the root-to-leaf
direction.

``
        if pid is not None:
            out.insert(0, pid)
            ``.``
``

recurse to get the parent's parent.

``
            self._get_parents(pid, out)
``

_get_childs collects the oids of the sample's children in the `out`
list, in order from root-to-leaf. take oids to include aliquotgroups.

``/_get_childs:
    def _get_childs(self, oid, out):
        ``.``
``

get the children. query directly for performancs (sample() would join
in the main sample idcontainer by default).

``
        res = self.db.qfad("select oid from centraxx_sample where parent = ?", oid)
``

if there are children, append them.

``
        for child in res:
            out.append(child["oid"])
``

returse to get the children of the children.

``
            self._get_childs(child["oid"], out)
``

patient gets patients and returns them as a list of Patient instances.

the parameters work analog to the sample method.

``/patient: #py
    def patient(self, patientids=None, pidc=None, sampleids=None, idc=None, trials=None, orgas:list=None, files:dict=None, verbose:list=None, verbose_all=False, like:list=None, order_by=None, top=None, print_query:bool=False, raw:bool=False):
        ``.``
``

init arrays to avoid mutable default parameters.

``
        if verbose is None:
            verbose = []
        if like is None:
            like = []
        if files is None:
            files = {}
``

vaa (verbose-all-array) holds all possible verbose options for patient.

`` #py
        vaa = [orga]
``

append the idcs for patient to the vaa array.  don't append idcs for
sample, cause then one patient with fifteen samples would come out as
fifteen result rows?

``
        vaa.extend(self._patientidcs(pidc))        
``


always join the patientid via verbose. put it as the first array element
for subsequent joins that might need it.

`` #py
        if not self.pidc(pidc) in verbose:
            verbose.insert(0, self.pidc(pidc))
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        files = self._concrete_idcs_dict(files, pidc=pidc)        
``

load the data from files into tables. see the method comment for _bcp
why we're doing this.

``
        filetables = self._bcp(files)
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
``

put the keys for the arguments into the verbose array.

``
        if orgas is not None:
            verbose.append(orga)
``

make an array of silent joins for fields that might get queried after
but shouldn't be included in the output.

`` #py
        silent = []
        if trials:
            silent.append(trial)
        if orgas:
            silent.append(orga)
``


make sure that the verbose array only contains keys from the
verbose-all-array.

// what about?
add the sampleid extra cause it strictly isn't allowed as a verbose
flag, but if verbose is used to orchestrate all joins it needs to be
in verbose for idc?

``
        if not _checkverbose(verbose, vaa):
            return None # throw error?
``

put the sampleids and patientids into idc, to handle them as just
another idcontainer for joining and in where.

``
        # todo check that self.sidc() is not in idc
        if idc is None:
           idc = {}
        if sampleids is not None:
           idc[self.sidc()] = sampleids
        if patientids is not None:
           idc[self.pidc(pidc)] = patientids
           
``

the select statements for optional joins by key.

`` #py
        selects = {
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],
            orga: [f"organisationunit.code as '{orga}'"],
            trial: [f"flexistudy.code as '{trial}'"],
        }
``

the join statements for optional joins by key. if the same join is
needed for two different keys they are filtered out later.

pull the values from the join dict, jd.

`` #py
        joins = {
            orga: self.jd["patient_to_orga"],
            trial: self.jd["patient_to_trial"]
        }
``

for any sample idc, join in sample, which is needed by
_append_idc_joins.

``
        for sidc in self._sampleidcs():
            joins[sidc] = self.jd["patient_to_sample"]
``

put together the select string for the query. always select
patientcontainer.

`` #py
        selectstr = self._selectstr(selects, verbose, ["patientcontainer.*"], idc)  
``

put together the join string for the query. join in verbose and
silent.

``
        joinstr = self._joinstr(joins, verbose + silent, idc, pidc=pidc)  
``

get the where string.

`` #py
        (wherestr, whereargs) = self._where(orgas=orgas, trials=trials, idc=idc, filetables=filetables, verbose=verbose, like=like)
        #print(whereargs)
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query. select distinct so that sample joins for
idcontainers etc don't result in a patient getting returned multiple
times if there's multiple samples.


`` #py
        query = f"select distinct {topstr} {selectstr} from centraxx_patientcontainer patientcontainer \n{joinstr} \nwhere {wherestr}"
        if order_by is not None:
            query += " " + self._order_by(order_by)
        if print_query:
           print(query)
``

get the result.

``
        res = self.db.qfad(query, whereargs)
``

remove the temporary tables holding bcp data.

``
        self._bcp_clean(filetables)
``

if raw is wished, return raw.

``
        if raw:
            return res
``

make patients from the result.

``
        pats = []
        for r in res:
            ``.``
``

collect the ids.

``
            ids = [ Identifier(id=dig(r, patientid), code=self.pidc(pidc)) ]
            for idc in self._patientidcs(pidc):
                if idc in r and r[idc] is not None:
                    ids.append( Identifier(id=dig(r, idc), code=idc.upper()) )
``

build the patient.

``
            pat = Patient(
              ids=Idable(ids=ids, mainidc=self.pidc(pidc)),
              orga=dig(r, orga)
            )
            pats.append(pat)
            #print("pat: " + str(pat))
``

return.

``/patient
        return pats
``

import.

``/import
from tram import Patient
``


the joindict entries that patient needs.

``/init/jd patient_to:
            "patient_to_orga": ["left join centraxx_patientorgunit patientorgunit on patientcontainer.oid=patientorgunit.patientcontainer_oid", "left join centraxx_organisationunit organisationunit on patientorgunit.orgunit_oid=organisationunit.oid"],
            "patient_to_trial": ["left join centraxx_patientstudy as patientstudy on patientstudy.patientcontainer = patientcontainer.oid", "left join centraxx_flexistudy as flexistudy on flexistudy.oid = patientstudy.flexistudy"],
            "patient_to_sample": ["left join centraxx_sample sample on sample.patientcontainer = patientcontainer.oid"]
``


trial gives trials.

``/trial: #py
    def trial(self):
        ``.``
``

return the trial codes for now.

``
        query = "select code from centraxx_flexistudy"
        res = self.db.qfad(query)
        return res
``

finding gets the laborfindings ("messbefund" / "begleitschein") for
sampleids or method.  it returns a list of Finding instances.

you can pass these to verbose: tr.patientid  // maybe also tr.values?

``/finding: #py
    def finding(self, sampleids=None, patientids=None, pidc:str=None, idc=None, methods=None, trials=None, values:bool=True, verbose:list=None, files:dict=None, verbose_all:bool=False, names:bool=False, top:int=None, print_query:bool=False, raw:bool=False):
        ``init``
        ``findings``
        ``values``
        ``ret``
``

init arrays to avoid multiple default parameters.

``/finding/init:
        if verbose is None:
            verbose = []
        if files is None:
            files = {}
``

vaa (verbose-all-array) holds all possible verbose options for patient.

``/finding/findings: #py
        vaa = [patientid] # include trial?
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
``

put the keys for the arguments into the verbose array.

``
        if trials is not None:
            verbose.append(trial)
``

for now always include the sampleid.

``
        if self.sidc() not in verbose:
            verbose.append(self.sidc())
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        files = self._concrete_idcs_dict(files, pidc=pidc)
``

load the data from files into tables. see the method comment for _bcp
why we're doing this.

``
        filetables = self._bcp(files)
``

build the query for findings.  later add recorded values to each finding.

put the sampleids and patientids into idc, to handle them as just another idcontainer
for joining and in where.

``
        if idc is None:
           idc = {}
        # todo check that self.sidc() is not in idc
        if sampleids is not None:
           idc[self.sidc()] = sampleids
        if patientids is not None:
           idc[self.pidc(pidc)] = patientids
``

get the idc part of the select string.

``
        selects = {
            self.sidc(): [f"idc_{self.sidc()}.psn as '{sampleid}'"],
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],                   
        }
        idcselectstr = self._selectstr(selects, verbose, [], idc)  
``

for any patient idc, join in patientcontainer, which is needed by
_append_idc_joins.

``
        joins = {
            trial: self.jd["sample_to_trial"]
        }
        for pidc in self._patientidcs(pidc):
            joins[pidc] = self.jd["sample_to_patient"]
``

get the join string for idcs.

``
        idcjoinstr = self._joinstr(joins, verbose, idc, pidc=pidc)
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query.

``
        query = f"""select {topstr} laborfinding.oid as "laborfinding_oid", laborfinding.*, labormethod.code as {method}, {idcselectstr}
        from centraxx_laborfinding as laborfinding

        -- go from laborfinding to sample
        left join centraxx_labormethod as labormethod on laborfinding.labormethod = labormethod.oid
        left join centraxx_labormapping as labormapping on labormapping.laborfinding = laborfinding.oid
        left join centraxx_sample sample on labormapping.relatedoid = sample.oid
        {idcjoinstr}"""
``

get the where string and append it to the query.

``
        (wherestr, whereargs) = self._where(idc=idc, methods=methods, trials=trials, filetables=filetables)

        query += " where " + wherestr
        if print_query:
            print(query)
            print(whereargs)
``

get the result.

``
        results = self.db.qfad(query, whereargs)
``

remove the temporary tables holding bcp data.

``
        self._bcp_clean(filetables)
``

for each of the findings, pull in the recorded values.

maybe only on --verbose = ["values"]

if names should be loaded, get the laborvalue display names. load them
once to avoid joining them in each time, is that quicker?

catalogentry and usageentry display names are loaded in _make_rec if
needed.

``/finding/values:
        if names is True:
            self.names_laborvalue = self.name(table="laborvalue")
``

now iterate the findings and get their recorded values.

``
        for i, finding in enumerate(results):
            if values != True: # todo put this outside of the loop?
                continue
            ``query``
            ``put``
``

construct the query for the recorded values.

todo prefetch units?

``/finding/values/query:
            query = f"""select recordedvalue.*, laborvalue.code as laborvalue_code, laborvalue.dtype as laborvalue_type, laborvalue.custom_catalog as laborvalue_catalog_oid, unit.code as laborvalue_unit
                from centraxx_laborfinding as laborfinding

                -- go from laborfinding to recorded value
                join centraxx_labfindinglabval as labfindinglabval on labfindinglabval.laborfinding = laborfinding.oid
                join centraxx_recordedvalue as recordedvalue on labfindinglabval.oid = recordedvalue.oid

                --go from labfindinglabval to the laborvalue for the messparam
                join centraxx_laborvalue laborvalue on labfindinglabval.laborvalue = laborvalue.oid

                --go from laborvalue to unit
                left join centraxx_unity unit on laborvalue.unit = unit.oid

                where laborfinding.oid = ?
            """
``

turn the result into recorded value objects. key the values by
laborvalue_code (the messparam code).

``
            recvals = self.db.qfad(query, finding['laborfinding_oid'])
            valsbycode = {}
            for recval in recvals:
              valsbycode[recval["laborvalue_code"]] = self._make_rec(recval, finding, names)
``

put the values to the finding.

``/finding/values/put:
            results[i]["values"] = valsbycode
``

if raw, return.

``/finding/ret:
        if raw:
            return results
``

make findings from the results.

``
        findings = []
        for res in results:
            finding = Finding(
                findingdate=dig(res, "findingdate"),
                method=res["method"],
                methodname=res["shortname"],
                patient=Idable(id=dig(res, patientid), code=self.pidc(pidc), mainidc=self.pidc(pidc)) if dig(res, patientid) is not None else None, 
                recs=res["values"] if "values" in res else None, # todo None ok?
                sample=Idable(id=res[sampleid], code=self.sidc(), mainidc=self.sidc()),
                sender=None
            )
            findings.append(finding)
``                     

return the findings with their respective values.

``/finding/ret
        return findings
``

import.

``/import
from tram import Finding
from tram import Rec, BooleanRec, NumberRec, StringRec, DateRec, MultiRec, CatalogRec
``

_make_rec makes a recorded value instance for finding from db results with display names if wished.

``/_make_rec:
    def _make_rec(self, recval, finding, names:bool=False) -> Rec:
        ``.``
``

make different rec val instances depending on the type. see the Rec
type attribute for an overview of the different types.

convert the boolean values from integer to boolean.

``
        out:Rec = None
        if recval["laborvalue_type"] == "BOOLEAN":
            val = True if recval["boolvalue"] == 1 else False
            out = BooleanRec(method=finding["method"], labval=recval["laborvalue_code"], rec=val)
``

take DECIMAL values from the numericvalue field.

somehow the cast to float seems necessary, if the Decimal from the db
result is passed, the value ends up being None.

if a number value isn't set, the db returns None (and not 0.0 or so).

``
        elif recval["laborvalue_type"] == "DECIMAL":
            #print(recval["laborvalue_code"])
            #print(recval)
            value = float(recval["numericvalue"]) if recval["numericvalue"] is not None else None
            out = NumberRec(method=finding["method"], labval=recval["laborvalue_code"], rec=value, unit=recval["laborvalue_unit"])
``

there are only four laborvalues for INTEGER, and they don't seem to be
findable with erweiterte suche. TODO what to do?

handle both STRING and LONGSTRING as StringRec.

``
        elif recval["laborvalue_type"] == "STRING" or recval["laborvalue_type"] == "LONGSTRING":
            out = StringRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["stringvalue"])
``

take DATE values from datevalue and LONGDATE values from
datevalueprecision, respectively.

``
        elif recval["laborvalue_type"] == "DATE":
            out = DateRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["datevalue"])
        elif recval["laborvalue_type"] == "LONGDATE":
            out = DateRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["datevalueprecision"])
``

for catalog, query the actual catalog entries. go from recordedvalue
to catalogentry via the recordedval_catentry table.

``
        elif recval["laborvalue_type"] == "CATALOG":
            # get the catalog code
            query = f"""select catalog.code as 'catalog_code' from centraxx_catalog as catalog
            where catalog.oid = ?""" # do this once for all catalogs on startup or finding() call?
            res = self.db.qfad(query, recval['laborvalue_catalog_oid'])
            catalog_code = res[0]["catalog_code"]
            # get the catalog entries
            query = f"""select catalogentry.code as 'catalogentry_code' from centraxx_recordedvalue as recordedvalue
            join centraxx_recordedval_catentry as recordedval_catentry on recordedval_catentry.recordedvalue_oid = recordedvalue.oid
            join centraxx_catalogentry as catalogentry on catalogentry.oid = recordedval_catentry.catalogentry_oid
            where recordedvalue.oid = ?"""
            res = self.db.qfad(query, recval['oid'])
            # get the catalogentry names if they are not already loaded, and cache them. maybe it's faster to load the whole names map once instead of joining them in each time?
            if names is True and self.names_catalogentry is None:
                self.names_catalogentry = self.name(table="catalogentry")
            entries = []
            value_name = {}
            for r in res:
                code = r["catalogentry_code"]
                entries.append(code)
                if names is True:
                    value_name[code] = self.names_catalogentry[code]
            
            out = CatalogRec(method=finding["method"], labval=recval["laborvalue_code"], catalog=catalog_code, rec=entries, rec_name=value_name)
``

for enumeration and option group, query the actual usage entries. go from recordedvalue
to usageentry via the recordedval_usageentry table.

for now, use a MultiRec type, that is the same as CatalogRec type,
except without catalog code?

``
        elif recval["laborvalue_type"] == "ENUMERATION" or recval["laborvalue_type"] == "OPTIONGROUP":
            query = f"""select usageentry.code as 'usageentry_code' from centraxx_recordedvalue as recordedvalue
            join centraxx_recordedval_usagentry as recordedval_usagentry on recordedval_usagentry.recordedvalue_oid = recordedvalue.oid
            join centraxx_usageentry as usageentry on usageentry.oid = recordedval_usagentry.usageentry_oid
            where recordedvalue.oid = ?"""            
            res = self.db.qfad(query, recval['oid'])

            # get the usageentry names if they are not already loaded, and cache them. maybe it's faster to load the whole names map once instead of joining them in each time?
            if names is True and self.names_usageentry is None:
                self.names_usageentry = self.name(table="usageentry")

            entries = []
            value_name = {}
            for r in res:
                code = r["usageentry_code"]
                entries.append(code)
                if names is True:
                    value_name[code] = self.names_usageentry[code]
            
            out = MultiRec(method=finding["method"], labval=recval["laborvalue_code"], rec=entries, rec_name=value_name)
``

else throw an exception.

``
        else:
            raise Exception(f"no record class for laborvalue of type {recval['laborvalue_type']}")
``

return.

``
        return out
``

method (messprofil) gets method(s) and their labvals (messparameter).
        
``/method:
    def method(self, methods=None, files:dict=None):
        ``.``
``

init files.

``
        if files is None:
            files = {}
``

put in concrete idcs.

``
        files = self._concrete_idcs_dict(files, pidc=pidc)
``

load the data from files into tables. see the method comment for _bcp
why we're doing this.

``
        filetables = self._bcp(files)
``

the query.

``
        query = f"""select laborvalue.code as labval, labormethod.code as "method"
from centraxx_labormethod labormethod
inner join centraxx_crftemplate crf_t
    on labormethod.crf_template=crf_t.oid
inner join centraxx_crftempsection crf_ts
    on crf_t.oid=crf_ts.crftemplate
inner join centraxx_crftempsection_fields crf_tsf
    on crf_ts.oid=crf_tsf.crftempsection_oid
inner join centraxx_crftempfield crf_tf
    on crf_tsf.crftempfield_oid=crf_tf.oid
inner join centraxx_laborvalue laborvalue
    on crf_tf.laborvalue=laborvalue.oid"""
``

add the where string.

``
        (wherestr, whereargs) = self._where(methods=methods, filetables=filetables)

        if wherestr:
          query += " where " + wherestr
        # print(query)
``

return the result.

``
        res = self.db.qfad(query, whereargs)
``

remove the temporary tables holding bcp data.

``
        self._bcp_clean(filetables)
``

if raw, return result as is.

`
        if raw:
            return res
`

get the names.  todo cache?

``
        methodnames = self.name(table="labormethod")
        labvalnames = self.name(table="laborvalue")
``

key the labvals by method code, add the names.

todo why are some labvals returned more than one in the query?

``
        out = {}
        for row in res:
            ``.``
``

add the method.

``
            methodcode = row["method"]
            if methodcode not in out:
                out[methodcode] = {}
                out[methodcode]["code"] = methodcode
                out[methodcode]["name_de"] = dig(methodnames, methodcode + "/de")
                out[methodcode]["name_en"] = dig(methodnames, methodcode + "/en")
                out[methodcode]["labvals"] = {}
``

add labvals to method.

``
            labvalcode = row["labval"]

            labval = {}
            labval["code"] = labvalcode
            labval["name_de"] = dig(labvalnames, labvalcode + "/de")
            labval["name_en"] = dig(labvalnames, labvalcode + "/en")            
            out[methodcode]["labvals"][labvalcode] = labval
``

return.

``
        return out
``


``/user:
    def user(self, usernames:list=None, emails:list=None, lastlogin=None, files:dict=None, verbose:list=None):
        ``.``
``

init arrays to avoid multiple default parameters.

``
        if verbose is None:
            verbose = []
        if files is None:
            files = {}
``
        

verbose all array holds the possible verbose options.

``
        vaa = [tr.address, tr.login]
``

put the keys for the given arguments into the verbose array for joining them in.

tr.address and tr.login are catch-alls for address and login related fields.

``
        if usernames:
            verbose.append(tr.username)
        if emails:
            verbose.append(tr.address)
        if lastlogin:
            verbose.append(tr.login)
``

load the data from files into tables. see the method comment for _bcp
why we're doing this.

``
        filetables = self._bcp(files)
``

todo wherestring and build query?

remove the temporary tables holding bcp data.

``
        self._bcp_clean(filetables)
``

turn the result into user instances.

``
        out = []
        for r in res:
            user = User(
                email=dig(r, tr.email),
                lastlogin=dig(r, tr.lastlogin),
                username=dig(r, tr.username),
            )
            out.append(user)
``

return.

``
        return out
``

the join dict entries for user.

``/init/jd participant_to:
            "participant_to_address": ["left join centraxx_participantaddress participantaddress on participantaddress.participant = participant.oid", "left join centraxx_address address on address.oid = participantaddress.oid"],
            "participant_to_credential": ["left join centraxx_credential credential on credential.participant = participant.oid"]
``

catalogentry gives the catalogentries per catalog.

``/catalogentry:
    def catalogentry(self):
        ``.``
``

query the catalogentries, joining in their cataloges.

``
        query = """select catalogentry.code as 'entry_code', catalog.code as 'catalog_code' from centraxx_catalogentry catalogentry
join centraxx_catalog catalog on catalogentry.catalog = catalog.oid"""
        res = self.db.qfad(query)
``

get the names for catalog entries and cataloges.

``
        catnames = self.name(table="catalog")
        entrynames = self.name(table="catalogentry")
``

put the output together. key by catalog code. add the display names.

``
        out = {}
        for row in res:
            entrycode = dig(row, "entry_code")
            catcode = dig(row, "catalog_code")
            # create the catalog
            if not catcode in out:
                out[catcode] = {}
                out[catcode]["code"] = catcode
                out[catcode]["name_de"] = dig(catnames, catcode + "/de")
                out[catcode]["name_en"] = dig(catnames, catcode + "/en")
                out[catcode]["entries"] = {}
            # add the entry
            entry = {}
            entry["code"] = entrycode
            entry["name_de"] = dig(entrynames, entrycode + "/de")
            entry["name_en"] = dig(entrynames, entrycode + "/en")        
            out[catcode]["entries"][entrycode] = entry
``

return.

``
        return out
``

usageentry gives the usageentries.

``/usageentry:
    def usageentry(self):
        ``.``
``

get the usageentries.

``
        query = "select code from centraxx_usageentry"
        res = self.db.qfad(query)
``

get the display names (todo cache)?

``
        names = self.name(table="usageentry")
``

put the names to the codes.

``
        out = {}
        for row in res:
            code = row["code"]
            out[code] = {}
            out[code]["name_de"] = dig(names, code + "/de")
            out[code]["name_en"] = dig(names, code + "/en")
            out[code]["code"] = code
``

return.

``
        return out
``

name gives the multilingual names for a code or all codes in a table.

the result is keyed by code and language like this:


"NUM_NMR_ISOLEUCINE_VALUE": {  
   "de": "Isoleucin",  
   "en": "Isoleucine"  
}


table: the name of the centraxx table without centraxx_ prefix  
code: a specific code, if none given, all code - name mappings for table are given  
lang: de|en  
ml_table: if the name of the table connecting to multilingualentry is not simlpy the queried table name followed by "_ml_name", give the connecting table's name here. eg: name('laborvaluegroup', ..., ml_name='labval_grp_ml_name')  


``/name:
    def name(self, table:str, code:str=None, lang:str=None, ml_table:str=None):
        ``.``
``

interlacing the table name assumes that the referencing pattern for
multilingual entries stays the same across table names.

``
        query = "select [" + table + "].code, multilingual.value as name, multilingual.lang as lang"
        query += " from [centraxx_" + table + "] as [" + table + "]"
``

put together the name for the ml_table.

``
        ml_name = ""
        if ml_table != None: # the name is different
            ml_name = "centraxx_" + ml_table
        else: # the name is the same
            ml_name = "centraxx_" + table + "_ml_name"
``

add it to the query.

``
        query += " inner join [" + ml_name + "] mlname on mlname.related_oid = [" + table + "].oid"
        query += " inner join centraxx_multilingualentry multilingual on mlname.oid = multilingual.oid"
``

restrict the query to specific lang or code if given.

``
        wherestrings = []
        args = []
        if code != None:
            wherestrings.append(self._whereparam("[" + table + "].code"))
            args.append(code)
        if lang != None:
            wherestrings.append(self._whereparam("multilingual.lang"))
            args.append(lang)
``

only add sql-where if needed.

``
        if len(wherestrings) > 0:
            query += " where "
            # join where clauses by and
            query += " and ".join(wherestrings)

        # print(query)
``

query.

``
        res = self.db.qfad(query, *args)
``

structure by code and lang and return.

``
        out = {}
        for line in res:
            code = line["code"]
            lang = line["lang"]
            if not code in out:
               out[code] = {}
            out[code][lang] = line["name"]
        return out
``

sidc returns the main idc code by which samples are referenced as
specified in the settings. 

``/sidc:
    def sidc(self) -> str:
        return self.settings['sampleid'][self.db.target]
``

sidc returns the main idc code by which patients are referenced as
specified in the settings. if a pidc argument is given, it is returned
instead of the settings' pidc.

``/pidc:
    def pidc(self, pidc:str=None) -> str:
        if pidc is not None:
            return pidc
        return self.settings['patientid'][self.db.target]
``

_sampleidcs returns the idcs from settings that are specific for sample.

rather make this a section in conf?

# idc holds idcontainer codes that should be queryable as command line flags 
idc:
  sample:
    - extsampleid
    - modul
    - tier
  patient:
    - mpi

``/_sampleidcs:
    def _sampleidcs(self) -> list:
        ``.``
``

the settings can list idc codes that are not applicable to this
target, skip them.

``
        out = []
        for idc in self.settings["idc"]:
            if idc in self._idckind and self._idckind[idc] == "SAMPLE":
                out.append(idc)
        # include the main sample idcontainer
        out.append(self.sidc())
        return out
``

patientidcs returns the idcs from settings that are specific for
sample.

``/_patientidcs:
    def _patientidcs(self, pidc:str=None) -> list:
        ``.``
``

the settings can list idc codes that are not applicable to this target, skip them.

``
        out = []
        for idc in self.settings["idc"]:
            if idc in self._idckind and self._idckind[idc] == "PATIENT":
                out.append(idc)
        # include the main patient idcontainer
        out.append(self.pidc(pidc))
        return out
``

_concrete_idcs replaces traction constants patientid and sampleid with their
respective idc for array.

``/_concrete_idcs:
    def _concrete_idcs(self, verbose, pidc=None):
        ``.``
``

fill in the concrete idcs when encountering patientid or sampleid.

``
        out = []
        for verb in verbose:
            if verb == patientid:
                out.append(self.pidc(pidc))
            elif verb == sampleid:
                out.append(self.sidc())
            else:
                out.append(verb)
        return out
``

_concrete_idcs_dict replaces traction constants patientid and sampleid with their
respective idc for dict.

``/_concrete_idcs_dict:
    def _concrete_idcs_dict(self, d, pidc=None):
        ``.``
``

fill in the concrete idcs when encountering patientid or sampleid.

``
        out = {}
        for key, val in d.items():
            if key == patientid:
                out[self.pidc(pidc)] = val
            elif key == sampleid:
                out[self.sidc()] = val
            else:
                out[key] = val
        return out
``


_fill_in_primary adds a reference to the given sample's primary sample,
if there is one.

``/_fill_in_primary:
    def _fill_in_primary(self, sample:Sample):
        ``.``
``

get the parent oids. 

``
        poids = []
        self._get_parents(sample.id("oid"), poids)
``

the first parent is the primary, take it.

``
        if len(poids) > 0:
            primary_oid = poids[0]
            ``.``
``

query the primary to get its sampleid, reference it from the sample as
Idable.

``
            primary = self.sample(oids=[primary_oid])[0]
            sample.primary = Idable(ids=primary.ids, mainidc=primary.mainidc)
``

_selectstr filters the selects by the verbose array and returns the
sql select string. selecta is for fields that should be selected
regardless if they're in the verbose array or not.

the idc argument assumes that the sample table is joined it. // todo is this still true?

``/_selectstr: #py
    def _selectstr(self, selects, verbose, selecta, idc):
        for verb in verbose:
            ``.``        
``

skip verbose entries that are not in the selects dict, they are
probably idc selects that are handled later.

``
            if not verb in selects:
                continue
``

put in the select line(s).

``
            for s in selects[verb]:
                selecta.append(s)
``

append idc selects.

``/_selectstr #py
        selecta = self._append_idc_select(selecta, idc, verbose)
``      

get the selections and joins as string.

`` #py
        selectstr = ", \n".join(selecta)
        return selectstr
``

_joinstr puts together the joins needed by verbose array and idc keys
and returns the sql join string.

``/_joinstr: #py
    def _joinstr(self, joins, verbose, idc, pidc=None):
        ``.``
``

first put in the idc joins, cause other joins might need them.

``
        joina = []
        joina = self._append_idc_join(joina, idc, verbose, joins, pidc=pidc)
``

now put in joins for verbose.

could you substract idc from verbose here cause there were already taken care of?

``
        for verb in verbose: 
            ``.``
``


skip verbose entries that are not in the joins dict, //they are 
probably idc joins that are handled later. ?true?

``
            if not verb in joins:
                continue
``

put in the join line(s). make sure that join clauses aren't included
double, for example both locationpath and locationname join in
samplelocation, so check that it's not already in the join array.

``
            for s in joins[verb]:
                if not s in joina:
                    joina.append(s)
``


get the joins as string.

`` #py
        joinstr = " \n".join(joina)
        return joinstr
``

_append_idc_select adds the sql select statements for an idc dict.

``/_append_idc_select:
    def _append_idc_select(self, selecta, idc, verbose):
        ``.``
``

put in the members of verbose touched by idc.

``
  idca = []
  for verb in verbose:
    if verb in self.settings["idc"]:
      idca.append(verb)
``    

make select strings and append them.

``
  for item in idca:
    selectstr = f"idc_{item}.psn as '{item}'"
    if not selectstr in selecta:
      selecta.append(selectstr)
``

return the selecta with appended strings.

``
  return selecta
``

_append_idc_join adds the sql join statements for an idc dict.

``/_append_idc_join: #py
    def _append_idc_join(self, joina, idc, verbose, joins, pidc=None):
        ``.``
``

put in the members of verbose touched by idc and the keys of idc into
a common array.

``
        idca = []
        for verb in verbose:
          if verb in self.settings["idc"] or verb == self.sidc() or verb == self.pidc(pidc):
            idca.append(verb)
        if idc is not None:
          idca.extend(idc.keys())
``

add a join for each member of the idc array.

the joins are different for idckind SAMPLE and PATIENT.

``
        for item in idca:
          ``intermediary``
          if self._idckind[item] == "SAMPLE":
            ``sample``
          elif self._idckind[item] == "PATIENT":
            ``patient``
          else:
            print(f"error: idcontainer kind {self._idckind[item]} not supported.")
``

put in idc-intermediary joins, for when sample joins in patient idcs and
needs patientcontainer for that or vice versa. 

``./intermediary:
          if item in joins:
            for s in joins[item]:
              if s not in joina:
                joina.append(s)
``


join in sampleidcontainer for SAMPLE. prefix it with idc_ instead of
sidc_, so that there can be one where-check that uses the idc_ prefix
for both patient and sample idcontainers.

when joining in idcontainers, we need to check their respective
idcontainer type. do this here as opposed to the where clause at the
end of the query, cause here if a idcontainer is not set checking here
just makes the field null in the result row, whereas checking in the
where clause it excludes the entire row.

``../sample:
        joinstr = f"left join centraxx_sampleidcontainer as idc_{item} on idc_{item}.sample = sample.oid and idc_{item}.idcontainertype = {self._idcoid[item]}"

        if not joinstr in joina:
          joina.append(joinstr)
``

join in idcontainer via patientcontainer for PATIENT:

``../patient:
        joinstr = f"left join centraxx_idcontainer as idc_{item} on idc_{item}.patientcontainer = patientcontainer.oid and idc_{item}.idcontainertype = {self._idcoid[item]}"
        if not joinstr in joina: # neccessary?
          joina.append(joinstr)
``

return the selecta with appended strings.

``/_append_idc_join
        return joina
``

_where returns the wherestring and args array for the provided
arguments (that are not None).

the user needs to make sure that whatever is referenced here is joined
into the query before.

the names are assumed to be the tr constants, like
e.g. tr.sampleid. like is an array of tr constants of the arguments
for which it checks likeness. we only check likeness for the first
passed string of an argument array. if for example
like=[tr.locationpath], it checks likeness of locationpaths[0].

make sure only one of sampleids or extsampleids is passed?

``/_where:
    def _where(self, idc={}, sampleoids:list=None, parentids:list=None, parentoids:list=None, patientids:list=None, trials:list=None, locationpaths:list=None, kitids:list=None, cxxkitids:list=None, categories:list=None, types:list=None, orgas:list=None, samplingdates=None, receiptdates=None, derivaldates=None, first_repositiondates=None, repositiondates=None, stockprocessingdates=None, secondprocessingdates=None, methods=None, filetables:dict=None, like=None, verbose=None): # -> (str, [])
        ``.``
``

init arrays to avoid mutable default parameters.

``
        if like is None:
            like = []
        if verbose is None:
            verbose = []
``

put the where-info for each field that could appear in the verbose
array into wheredict along with the passed arguments.

arr: the array of values to check against
field: the table and field where it should match. 

``
        wheredict = { 
          trial: { "arr": trials, "field": "flexistudy.code" },
          locationpath: { "arr": locationpaths, "field": "samplelocation.locationpath" },
          method: { "arr": methods, "field": "labormethod.code" },
          kitid: { "arr": kitids, "field": "samplekit.kitid" },
          cxxkitid: { "arr": cxxkitids, "field": "samplekit.cxxkitid" },
          category: { "arr": categories, "field": "sample.dtype" },
          type: { "arr": types, "field": "sampletype.code" },          
          orga: { "arr": orgas, "field": "organisationunit.code" },
          parentid: { "arr": parentids, "field": "parentidc.psn" },
          parentoid: { "arr": parentoids, "field": "sample.parent" },
          sampleoid: { "arr": sampleoids, "field": "sample.oid" },          
          samplingdate: { "arr": samplingdates, "field": "sample.samplingdate", "type": "date" },
          receiptdate: { "arr": receiptdates, "field": "sample.receiptdate", "type": "date" },
          derivaldate: { "arr": derivaldates, "field": "sample.derivaldate", "type": "date" },
          first_repositiondate: { "arr": first_repositiondates, "field": "sample.first_repositiondate", "type": "date" },
          repositiondate: { "arr": repositiondates, "field": "sample.repositiondate", "type": "date" },
          stockprocessingdate: { "arr": stockprocessingdates, "field": "sample.stockprocessingdate", "type": "date" },
          secondprocessingdate: { "arr": secondprocessingdates, "field": "sample.secondprocessingdate", "type": "date" }
        }
``

add the passed idcs to the wheredict.

there could be items in verbose that are queried via the idc (for
example?), get them with the intersection call.

``
        idckeys = [] if idc is None else idc.keys()
        possibleidcs = self.settings["idc"] + [self.sidc()] # also add self.pidc(pidc)? todo
        #print("verbose:")
        #print(verbose)
        idca = list(idckeys) + list(set(verbose).intersection(possibleidcs))
        for item in idca:
            wheredict[item] = {
                                "arr": idc[item] if idc is not None and item in idc else None,
                                "field": f"idc_{item}.psn"
                             }
        #print("wheredict:")
        #print(wheredict)
``

stick together where clauses and arguments that covers the args that
are not None and the constants in verbose. return the wherestring and
args array.

``
        (wherearr, whereargs) = self._wherebuild(wheredict, like, verbose, filetables)

        wherestr = " and ".join(wherearr)
``

return.

``
        return (wherestr, whereargs)
``

_wherebuild builds wherestrings and fills whereargs.

``/_wherebuild:
    def _wherebuild(self, wheredict, likearr:list=None, verbose:list=None, filetables:dict=None): # ([]string, [])
        ``.``
``

init arrays to avoid mutable default parameters.

``
        if likearr is None:
            likearr = []
        if verbose is None:
            verbose = []
``

add where clauses to wherestrs and their respective arguments to
whereargs.

``
        wherestrs = []
        whereargs = []
``

iterate the passed wheredict. it contains all possible joins. build
where clauses for joins where the "arr" field is set.

key is one of the tr constant strings, e.g. tr.locationpath.

``

        for key, row in wheredict.items():
            #print("key:" + key)

            # somehow printing here stops the keys from being iterated in the loop. why?
            #print("field: " + row["field"])

            # not used
            if key not in filetables and (row["arr"] == None or len(row["arr"]) == 0):
                continue

            # both file and array: error for now.
            # if key in filetables and row["arr"] is not None:
            #    raise Exception(f"pass either a list or a file for {key}, not both.")

            if likearr is not None and key in likearr:
                ``like``
            elif (row["arr"] is not None or key in filetables) and "type" in row and row["type"] == "date":
                ``date``
            else:
                ``exact``
``

we only look at wheredict entries where there is something in the
"arr" field.

if should we check for likeness for this key, put in a like clause.

``/_wherebuild/like:
                # put in an or-chain of like checks over all elements
                s = "(" + self._wherelikes(row["field"], len(row["arr"])) + ")"
                wherestrs.append(s)
                whereargs.extend(row["arr"])
``

if it's a date check, check that it's between the two values of the
array passed as date parameter.

CAST removes the time component, this is needed for getting samples
from one day (when both dates are the same).

ISNULL handles missing start or end date. is this smart, or rather
check for >=, <= etc if only one date is given?

for null checks, instead of the date tuple, 'NULL' is passed. maybe a
bit hacky?

``/_wherebuild/date:
               if row["arr"] == 'NULL':
                   wherestrs.append("(" + row['field'] + " is NULL)")
               else:
                   s = f"(CAST(" + row['field'] + " as date) between ISNULL(?, " + row['field'] + ") and ISNULL(?, " + row['field'] + "))"
                   wherestrs.append(s)
                   whereargs.extend(row["arr"])
``

else put in an exact-match clause.

open the where string.

``/_wherebuild/exact:
                wherestr = "("
``

make null checks extra, e.g. '(kitid is NULL or kitid in (1, 2, 3))'.

if is there a 'NULL' in the array, put in a NULL check and remove it
from the array, so it doesn't mess with the where-arguments later.

``
                needsor = False
                if row["arr"] is not None and 'NULL' in row["arr"]:
                    row["arr"].remove("NULL")
                    wherestr += row["field"] + " is NULL"
                    needsor = True
``

if there is anything left in the array, make the in-list part of the
wherestring with the ?-placeholder string.

``
                if row["arr"] is not None and len(row["arr"]) > 0:
                    if needsor:
                        wherestr += " or "
                    placeholder = traction._sqlinplaceholder(len(row["arr"])) # todo put in package? tr._sqlinplaceholder
                    wherestr += row["field"] + " in " + placeholder # e.g. samplelocation.locationpath in (?, ?, ?)
                    # if something comes next, chain it with or
                    needsor = True
``

read the file content from bcp table.

``
                if key in filetables:
                    if needsor:
                        wherestr += " or "
                    wherestr += row["field"] + " in "
                    wherestr += f"(select stdin from trac.dbo.{filetables[key]})"
``

close the exact-match wherestr with ) and put the wherestring and its arguments
into their corresponding arrays.

``
                wherestr += ")"
                wherestrs.append(wherestr)
                if row["arr"] is not None:
                    whereargs.extend(row["arr"])
``


after the loop return.

``/_wherebuild/
        return (wherestrs, whereargs)
``

    
_sqlinplaceholder returns a string like (?, ?, ?, ? ...) with n question marks for sql in.

``/_sqlinplaceholder:
    def _sqlinplaceholder(n):

        # put this in a package sqlutil?

        out = "("
        for i in range(n):
            out += "?"
            if i < n - 1:
                out += ","
        out += ")"
        return out
``

_whereparam gives a ?-parameterized sql where expression for name
equal or like parameter for use in queries.

``/_whereparam:
    def _whereparam(self, name, like:bool=None):
        if like == None or like == False:
            return name + " = ?"
        else:
            return name + " like '%' + ? + '%'"
``

_wherelike gives a ?-parameterized sql where like expression.

``/_wherelike:
    def _wherelike(self, name):
        return name + " like '%' + ? + '%'"

``

_wherelikes gives a ?-parameterized sql of or-joined where-like
expressions, as many as given n.

``/_wherelikes:
    def _wherelikes(self, field, n):
        a = []
        for i in range(n):
            a.append(field + " like '%' + ? + '%'") # the sql takes literal plusses like here
        return " or ".join(a)
``

_top returns an injection-safe top string, for, e.g. `select top 100 * from table`, if
top is None return an empty string.

``/_top:
    def _top(self, top):
        ``.``
``

exit if the top param isn't a number. better use a sql building library for that?

``
        if top is not None:
           if not isnumber(top):
               raise Exception(f"top param {top} needs to be a number")
           return f"top {top}"
        return ""
``

_order_by returns an injection safe order by string.

``/_order_by:
    def _order_by(self, order_by):
        ``.``
``

exit if the order by parameter isn't an identifier.

``
        if not isidentifier(order_by):
            raise Exception(f"order_by param {order_by} needs to be an sql identifier.")
        return f"order by {order_by}"
``

_idcinit makes a mapping of idcontainers from their code (lower-case) to respective oid and kind.

``/_idcinit:
    def _idcinit(self):
        ``.``
``

get the codes and oids.

``
        query = "select code, oid, kind from centraxx_idcontainertype"
        res = self.db.qfad(query)
``

return idcontainer oids and kinds keyed by their code.

``
        self._idcoid = {}
        self._idckind = {}
        for row in res:
          self._idcoid[row["code"]] = row["oid"]
          self._idckind[row["code"]] = row["kind"]
``

_checkverbose makes shure that only allowed keys are in the verbose array. 

``/_checkverbose:
def _checkverbose(verbose, possible):
    for verb in verbose:
        if not verb in possible: 
            print(f"error: verbose entry {verb} must be in {possible}.")
            return False
    return True
``

_bcp copies files to the db server and inserts each into a temporary
table in the trac database by calling the bcp command line tool. it
takes a map of tr constants and relative file paths.  it returns a map
of the same tr constants and the table names the files ended up in.

we use bcp for getting file data to the server, cause if you feed the
data from a file directly to a query via query parameters you
relatively quickly hit an upper limit as only a maximum of 2100 query
parameters is allowed.  to bulk load data from a file into an
openrowset it must be on the server. so, the way seems to be, get the
data to the server, then bulk load or query it.

``/_bcp:
    def _bcp(self, files:dict): # -> dict
        ``.``
``

iterate the tr constants and file paths:

``
        out = {}
        for key, path in files.items():
            ``.``
``

create the table to copy to and remember its name.

``
            bcptable = self._bcp_table(path)
            out[key] = bcptable
``

run bcp.

``
            info = self.db.info
            subprocess.run(["bcp", bcptable, "in", path, "-S", info["server"], "-d", "trac",  "-U", info["username"], "-P", info["password"], "-q", "-c", "-t", ",", "-u", "-r", "\n"], stdout=open(os.devnull, 'wb'))
``

this inserts the data from the local file into the table on the server.

the bcp flags used are:

-u: trust server certificate
-t: field terminator
-r: row terminator  todo find the row terminator (dos/unix) from file
-q: quoted identifier

the bcp output is redirected to /dev/null as to not appear on the screen.

after the loop, return the table names keyed by tr constant.

``/_bcp
        return out
``

import subprocess and os.

``/import
import subprocess
import os
``

_bcp_table creates a table with one column called stdin for the
contents of a file to be read into and returns the table name. it
ensures that the table didn't exist before by using a combination of
the file name and a random number as table name.

``/_bcp_table:
    def _bcp_table(self, path:str):
        ``.``
``

get the file name without path and suffix.

flatten all non letter and number chars to underscore.

``
        stem = pathlib.Path(path).stem
        stem = re.sub(r"[^A-Za-z0-9]", "_", stem)
``

make sure that the table doesn't exist by appending a random number,
retrying with a different random number as long as a name already exists.

``
        rand = int(random.random() * 1000)
        name = stem + "_" + str(rand)
        while self._tbl_exists("trac", name):
            rand = int(random.random() * 1000)
            name = stem + "_" + str(rand)
``

create the table. todo: does this need to run on the same cursor as
the the table existence checking to ensure atomicity?

``
        #print(name)
        self.db.query(f"create table trac.dbo.{name} ( stdin varchar(255) )")
``

return the tablename.

``
        return name
``

import.

``/import
import pathlib
import random
``

_bcp_clean drops the tables that were created with _bcp after the
query using their data was run. it takes the dict of filetables that
was returned by _bcp.

``/_bcp_clean:
    def _bcp_clean(self, filetables:dict):
        ``.``
``

go over the tables and drop them.

``
        for key, tablename in filetables.items():
            self.db.query(f"use trac; drop table trac.dbo.{tablename}")  # todo is kairos_spring used again after this?
``

_tbl_exists returns whether a given table exists in a database.

``/_tbl_exists:
    def _tbl_exists(self, db, table):
        try:
            res = self.db.qfad(f"select * from {db}.information_schema.tables where table_name = ?", table)
            return len(res) > 0
        except Exception as e:
            print("traction: " + str(e))
            print("is the database 'trac' created? `create database trac`")
``

floatornull casts to float or returns None. somehow the values passed
to Amount need float casts, and float casts don't accept None.

``/floatornull:
def floatornull(x):
    if x is None:
        return None
    return float(x)
``

get_ids returns a list of string ids from a list of Idables (Sample or
Patient).

``/get_ids:
def get_ids(idables:list, code:str=None) -> list:
    return [ x.id(code) for x in idables ]
``

isnumber returns if a string is a number to prevent sql injection.  is
this handled better by an existing library function?

``/isnumber:
def isnumber(a) -> bool:
    return re.match(r"^[0-9](.[0-9]*)?$", a)
``

isidentifier returns whether a string is a sql identifier to prevent
sql injection.  like isnumber, could this be handled better by a library?

``/isidentifier:
def isidentifier(a) -> bool:
    return re.match(r"^[A-Za-z_0-9\.]+$", a)
``

import re.

``/import
import re
``

idable_csv writes a list of Idables to the given csv file. the given
idcontainers are included as columns. if no idcontainers are given, all
are included.

``/idable_csv:
def idable_csv(idables:list, filename:str=None, *idcs) -> str:
    ``.``
``

if no idables return. 

``
    if idables is None or len(idables) == 0: # todo throw error?
        print("no idables")
        return None
``

open the file.

``
    with open(filename, "w") as f:
        ``write``
``

make a csv writer.

``./write:
        writer = csv.writer(f, delimiter=",")
``

take as colum names the keys of the iddict from the first idable.

``
        writer.writerow(list(idables[0].iddict(*idcs).keys()))
``

write the list of dict items for each idable.

``
        for idable in idables:
            d = idable.iddict()
            writer.writerow(list(d.values()))
``

return the name of the file.

``
    return filename
``

import csv.

``/import
import csv
``


finding_csv writes a list of Findings along their recorded values to
the given csv file, the recorded values in the same row as their
respective finding.

``/finding_csv:
def finding_csv(findings:list, filename:str=None, delim:str=",", delim_cmp:str=",") -> str:
    ``.``
``

if no findings return. 

``
    if findings is None or len(findings) == 0: # todo throw error?
        print("no findings")
        return None
``

make dicts from the findings and pull in the recorded values.

collect a list of all the csv column names, so that values end up in
the right columns when writing csv.

``
    fdicts = []
    colnames = []

    for finding in findings:
        ``build fdict``
``

get the dict for the finding, delete the recs field.

``./build fdict:
        fdict = finding.__dict__.copy()
        del fdict["recs"]
``

if it's the first row, remember the finding field names for the csv
header. they should be the same for all findings.

``
        if len(colnames) == 0:
            colnames.extend(list(fdict.keys()))
``

pull in the recorded values.

``
        for code, rec in finding.recs.items():
            ``pull rec``
``

for each recorded value, make a field cmp_t_CODE holding the type and
cmp_v_CODE holding the value(s).

findings come with different recorded values, if this recorded value's
labval hasn't been encountered yet, remember it as column name.


``./pull rec:
            tkey = f"cmp_t_{rec.labval}"
            vkey = f"cmp_v_{rec.labval}"
            if tkey not in colnames:
                colnames.append(tkey)
            if vkey not in colnames:
                colnames.append(vkey)
``

go through the recorded values by type.

``
            if isinstance(rec, BooleanRec):
                fdict[tkey] = "BOOL"
                fdict[vkey] = rec.rec
``

for number.

``
            if isinstance(rec, NumberRec):
                fdict[tkey] = "NUMBER"
                fdict[vkey] = rec.rec
``

for string.

``
            if isinstance(rec, StringRec):
                fdict[tkey] = "STRING"
                fdict[vkey] = rec.rec
``

for date.

``
            if isinstance(rec, DateRec):
                fdict[tkey] = "DATE"
                fdict[vkey] = rec.rec
``

for multi and catalog rec, put all entries in it's rec list into one field.

``
            if isinstance(rec, MultiRec):
                fdict[tkey] = "MULTI"
                fdict[vkey] = delim_cmp.join(rec.rec)
            if isinstance(rec, CatalogRec):
                fdict[tkey] = "CATALOG"
                fdict[vkey] = delim_cmp.join(rec.rec)
                
``

after adding the recorded values append the finding dict.

``../
        fdicts.append(fdict)
``

after the loop open the csv file.

``/finding_csv
    with open(filename, "w") as f:
        ``write``
``

make a csv writer. pass the field names from all findings.

``./write:
        writer = csv.DictWriter(f, fieldnames=colnames, delimiter=delim)
``

write the header.

``
        writer.writeheader()
``

write the csv rows for each finding (and its recorded values).

``
        for fdict in fdicts:
            writer.writerow(fdict)
``

return the name of the file.

``
    return filename
``
