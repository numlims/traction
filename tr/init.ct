# traction

commonly used getters (and setters?) for centraxx db.

``//__init__.py: #py
``import``
``const``

``_checkverbose``
``floatornull``
``get_ids``
``isnumber``
``isidentifier``
``_dextend``
``_mvlists``
``_uniq``

``idable_csv``
``finding_csv``

class traction:
    ``init``

    ``sample``
    ``_get_parents``
    ``_get_childs``
    ``patient``
    ``trial``
    ``finding``
    ``method``
    ``user``
    ``catalogentry``
    ``usageentry``
    ``name``
    
    ``sidc``
    ``pidc``
    
    ``_selectstr``
    ``_joinstr``
    ``_append_idc_select``
    ``_append_idc_join``
    ``_where``
    ``_whereexact``
    ``_wheredate``    
    ``_sqlinplaceholder``
    ``_whereparam``
    ``_wherelike``
    ``_wherelikes``
    ``_top``
    ``_order_by``    
    ``_idcinit``
    ``_make_rec``
    
    ``_sampleidcs``
    ``_patientidcs``
    ``_concrete_idcs``
    ``_concrete_idcs_dict``
    
    ``_fill_in_primary``

    ``_makemove``
    ``_readfiles``
    ``_maketables``
    ``_cleartt``
``

at the package level are a series of constants that can be used in
function calls, e.g. sample(..., verbose=[tr.parentid,
tr.locationpath]).

maybe keep the names in lowercase so that they are the same as the
keys in the returned json?

``/const: #py
address = "address"
appointment = "appointment"
category = "category" # MASTER, ALIQUOTGROUP, DERIVED. dtype in db.
concentration = "concentration"
cxxkitid = "cxxkitid"
creationdate = "creationdate" 
derivaldate = "derivaldate" # aufteilungsdatum / date of distribution
email = "email"
initialamount = "initialamount"
initialunit = "initialunit"
first_repositiondate = "first_repositiondate" # datum der ersten einlagerung / date of first storage (not in fhir). is identical to derivaldate. first_repositiondate in db.
method = "method"
kitid = "kitid"
lastlogin = "lastlogin"
login = "login"
locationname = "locationname"
locationpath = "locationpath"
orga = "orga"
parentid = "parentid"
parentoid = "parentoid"
patientid = "patientid"
project = "project"
receiptdate = "receiptdate" # eingangsdatum / date of receipt. receiptdate in db.
receptacle = "receptacle"
repositiondate = "repositiondate" # datum der letzten einlagerung / most recent storage date. 
restamount = "restamount"
restunit = "restunit"
sampleid = "sampleid"
sampleoid = "sampleoid"
samplingdate = "samplingdate" # entnahmedatum / extraction date.
secondprocessing = "secondprocessing"
secondprocessingdate = "secondprocessingdate"
stockprocessing = "stockprocessing"
stockprocessingdate = "stockprocessingdate"
trial = "trial"
type = "type" # sampletype (EDTA, stool etc) in db.
username = "username"
values = "values"
xposition = "xposition"
yposition = "yposition"
``

__init__ takes the db target either as string or dbcq object.

``/init: #py
    def __init__(self, target):
        ``.``
``

get the settings. if the settings file is missing, cnf creates it and
asks the user to edit it.

``
        self.settings = cnf.makeload(path=".traction/settings.yaml", root=cnf.home, fmt="yaml", make=cnftemplate)        
``

if no settings, do nothing. 

``
        if self.settings == None:
            raise Exception("no settings.")
            return
``

either pass a string argument to dbcq or use dbcq instance directly.

`` #py
        if isinstance(target, str):
            self.db = dbcq(target)
        elif isinstance(target, dbcq): 
            self.db = target
        else:
            raise Exception("target needs to be string or dbcq instance")
``

cache the id containers' oids and kinds by code.

``
        self._idcinit()
        #print(f"_idcoids: {self._idcoids}")
``

make a join-dict, jd, that holds joins from table a to table b.

init jd here, cause it needs to reference self at one point for joining in an idc_ table.

``
        self.jd = {
            ``jd sample_to``
            ,
            ``jd patient_to``
            ,
            ``jd participant_to``
        }
``

set the display name caches.

``
        self.names_labval = None
        self.names_catalogentry = None
        self.names_usageentry = None
``

import dbcq and cnf.

``/import: #py
from dbcq import *
import cnf
``

add a variable that holds the conf template.

``/const
cnftemplate = """
# settings for traction.

# sampleid sets the idcontainertype code that is used when searching for sampleid.
# put in a code per db target.
sampleid: 
  <db target>: <an idcontainertype code, e.g. SAMPLEID>
# patientid sets the idcontainertype code that is used when searching for patientid.
# put in a code per db target.
patientid: 
  <db target>: <an idcontainertype code, e.g. LIMSPSN>

# idc holds additional idcontainertype codes that will be queryable as command line flags.
idc:
 - <an idcontainertype code>
 - <another idcontainertype code>
"""
``

sample gets sample(s) and returns them as a list of Sample instances.

pass sampleids and other values to filter for as lists of strings,
e.g. `sampleids=["a", "b", "c"]`.

use the idc param to filter for idcontainer lists by passing a dict of
lists keyed by idcontainer code, e.g. `idc={"extsampleid": ["a", "b", "c"]}`.

put info that should be joined into the result into the verbose array,
e.g.  `verbose=[tr.locationpath]`. to join in everything, say
`verbose_all=True`. this is slower than non-verbose.

pass dates as a tuple of from and to datetime, e.g. `samplingdates=(datefrom, None)`.

to check via like as opposed to exact, put the respective fields into
the like array, e.g. `like=[tr.locationpath]`.

``/sample: #py
    def sample(self, sampleids:list=None, oids:list=None, idc=None, patientids:list=None, pidc:str=None, parentids:list=None, parentoids:list=None, locationpaths:list=None, trials:list=None, kitids:list=None, cxxkitids:list=None, categories:list=None, types:list=None, orgas:list=None, samplingdates=None, receiptdates=None, derivaldates=None, first_repositiondates=None, repositiondates=None, stockprocessingdates=None, secondprocessingdates=None, files:dict=None, verbose:list=None, verbose_all=False, primaryref:bool=False, incl_parents:bool=False, incl_childs:bool=False, incl_tree:bool=False, like:list=None, missing=False, order_by=None, top=None, print_query:bool=False, raw:bool=False):
        ``.``
``

init arrays.  don't set them as mutable default parameters
(e.g. verbose=[]), cause they would then retain their values across
method calls. see
https://www.geeksforgeeks.org/python/use-mutable-default-value-as-an-argument-in-python/

``
        if verbose is None:
            verbose = []
        if like is None:
            like = []
        if files is None:
            files = {}
        if idc is None:
            idc = {}
``


these are all possible verbose options (verbose-all-array).

let sampleid be the first element in vaa so it gets joined in first
for subsequent joins that depend on it.

`` #py
        # print("try:" + tr.sampleid)
        vaa = [cxxkitid, kitid, locationname, locationpath, orga, parentid, 
               project, receptacle, type,
               secondprocessing, stockprocessing, trial]
``

append the idcs for patient and sample to the vaa array.  

``
        vaa.extend(self._patientidcs(pidc))
        vaa.extend(self._sampleidcs())                
``

always join in the sampleid, as the first array element for subsequent
joins that might need it.

`` #py
        if not self.sidc() in verbose:
            verbose.insert(0, self.sidc())
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        #files = self._concrete_idcs_dict(files, pidc=pidc)
        #print("files:")
        #print(files)
``


put the keys for the given arguments into the verbose array, so that
they land in the join, so that the wherestring can access the
joined-in fields.

`` #py

        if trials:
            verbose.append(trial)
        if locationpaths:
            verbose.append(locationpath)
        if kitids:
            verbose.append(kitid)
        if cxxkitid:
            verbose.append(cxxkitid)
        if parentids:
            verbose.append(parentid)
        if orgas:
            verbose.append(orga)
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
        #print("verbose:")
        #print(verbose)
``

make sure that the verbose array only contains keys from the verbose-all-array.

``
        if not _checkverbose(verbose, vaa): 
            return None # throw error?
``

after the verbose array was filled walk the sample tree if needed.

there are two cases where we walk the sample tree:

(a) including other samples.

if the sample's parents, children or it's whole tree should be
included in the result, first run this call, take the sample oids
returned, then add the oids of the parents / childs / tree samples (in
order from root to leaf), and then run the query with its verboses for
all the sample oids.

(b) referencing the primary sample for each derived sample.

if each derived sample should reference its primary, also
run the call, and then fill in the primary field for each sample.

at first it was thought to do the primary referencing via verbose, but
then each verbose all call would include the primary references, which
might slow it down?

check if we walk the sample tree.

``
        if incl_parents or incl_childs or incl_tree or primaryref:
            ``incl``
``

we fire the call with all the arguments except incl_*, and raw.

we pass only verbose if we add primary references, cause then we only
run the call once. if we include tree samples later we don't pass
verbose, cause we eventually run the call again for all tree samples,
passing verbose here would slow it down.

it shouldn't make a difference to pass verbose_all for primary, cause
verbose should be filled in any case.

``/sample/incl:
            verbosepass = []
            if primaryref:
                verbosepass = verbose
``

fire the call, then add to the result.

``
            res = self.sample(sampleids=sampleids, idc=idc, parentids=parentids, parentoids=parentoids, patientids=patientids, pidc=pidc, trials=trials, locationpaths=locationpaths, kitids=kitids, cxxkitids=cxxkitids, categories=categories, samplingdates=samplingdates, receiptdates=receiptdates, derivaldates=derivaldates, first_repositiondates=first_repositiondates, repositiondates=repositiondates, stockprocessingdates=stockprocessingdates, secondprocessingdates=secondprocessingdates, verbose=verbosepass, verbose_all=False, like=like, missing=missing, order_by=order_by, top=top, print_query=print_query)
``

proceed differently if primary info should be added or if samples from
the tree should be included.

``
            if primaryref:
                for sample in res:
                    self._fill_in_primary(sample)
                return res
``

when including samples from the tree, take all the sample oids.

use oids to support aliquotgroups.

``/sample/incl
            
            s_oids = get_ids(res, "oid")
``

withincl holds all the sampleids that eventually get queried.

``
            withincl = []
``

now put in the sample oids of parents, childs or the whole tree.

``
            for s_oid in s_oids:
               if incl_parents:
                   ``parents``
               if incl_childs:
                   ``childs``
               if incl_tree:
                   ``tree``
``

if the parent sampleids should be included, get them from root to
leaf. collect them into the pids list.

``/sample/incl/parents:
                   p_oids = []
                   self._get_parents(s_oid, p_oids)
``

put the parent oids in, followed by our sample oid.

``
                   withincl.extend(p_oids)
                   withincl.append(s_oid)
``

if the child oids should be included, get them from sample to leaf.

``/sample/incl/childs:
                  c_oids = []
                  self._get_childs(s_oid, c_oids)
``

put the child oids in, preceeded by our sample oid.

``
                  withincl.append(s_oid)
                  withincl.extend(c_oids)
``

if the whole tree should be included, get the root, and include all
children from there.

``/sample/incl/tree:
                  p_oids = []
                  self._get_parents(s_oid, p_oids)
                  if len(p_oids) > 0:
                      root = p_oids[0]
                  else:
                      root = s_oid
``

get the child oids from root.

``
                  c_oids = []
                  self._get_childs(root, c_oids)
``

append the root oid, then the child oids.

``
                  withincl.append(root)
                  withincl.extend(c_oids)
``

after filling withincl, filter out recurring sampleids. keep each id
where it first appeared in the array to preserve tree dependencies.


``/sample/incl
            withincl = list(dict.fromkeys(withincl))
``

using dict.fromkeys here depends on python dicts preserving insertion order
since python 3.7.

now run the query for all the sampleids with the verboses. the
verboses should contain all the query parameters from the original
call. in the call here we don't pass the query parameters from the
original call, cause we used them already to get the sampleids, and
here they could filter out parent/child/tree samples we'd like to keep.

``
            return self.sample(oids=withincl, verbose=verbose, print_query=print_query, raw=raw) # todo pass verbose_all?
``

put the arguments in a dict of lists.

``
        lists = {
          sampleoid: oids,
          parentid: parentids,
          parentoid: parentoids,
          locationpath: locationpaths,
          trial: trials,
          kitid: kitids,
          cxxkitid: cxxkitids,
          category: categories,
          orga: orgas,
          samplingdate: samplingdates,
          receiptdate: receiptdates,
          derivaldate: derivaldates,
          first_repositiondate: first_repositiondates,
          repositiondate: repositiondates,
          stockprocessingdate: stockprocessingdates,
          secondprocessingdate: secondprocessingdates
        }
``

resolve the sampleid and patientid shortcut by putting their lists
into the idc dict.

``
        _dextend(idc, self.sidc(), sampleids)
        _dextend(idc, self.pidc(pidc), patientids)
``

now idc holds all parameters queryable as idcontainers.

put files and all lists larger than 100 items into temporary
tables.

``
        (tmptables, idctmptables) = self._makemove(files, lists, idc, 100, pidc=pidc)
``

jselect holds statements for optional joins by key.

rename the field of the main sample idcontainer to sampleid.

`` #py
        jselects = {
            self.sidc(): [f"idc_{self.sidc()}.psn as '{sampleid}'"],
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],                   
            cxxkitid: [f"samplekit.cxxkitid as '{cxxkitid}'"],
            #sampleid: [f"sidc.psn as '{sampleid}'"],
            parentid: [f"parentidc.psn as '{parentid}'"],
            kitid: [f"samplekit.kitid as '{kitid}'"],
            locationname: [f"samplelocation.locationid as '{locationname}'"], 
            locationpath: [f"samplelocation.locationpath as '{locationpath}'"],
            type: [f"sampletype.code as '{type}'"], # is there a type field already?
            stockprocessing: [f"stockprocessing.code as '{stockprocessing}'"],
            secondprocessing: [f"secondprocessing.code as '{secondprocessing}'"],
            project: [f"project.code as '{project}'"],
            #patientid: [f"patidc.psn as '{patientid}'"],
            receptacle: [f"receptable.code as '{receptacle}'"],
            orga: [f"organisationunit.code as '{orga}'"],
            trial: [f"flexistudy.code as '{trial}'"],
        }
``

lselects holds the local selects for this table, for field renames.

put sample.* first, that it doesn't overwrite field of the renames?

``
        lselects = [
          f"sample.amountrest as {restamount}",
          f"sample.appointmentnumber as {appointment}",
          f"sample.dtype as {category}",
          f"sample.oid as {sampleoid}",
          f"sample.parent as {parentoid}",
          "sample.*"
        ]
``

the join statements for optional joins by key. if the same join is
needed for two different keys (e.g. locationname and locationpath),
filter them out later.

pull the values from the join dict, jd.

`` #py
        joins = {
            cxxkitid: self.jd["sample_to_samplekit"],
            parentid: self.jd["sample_to_parentid"],
            kitid: self.jd["sample_to_samplekit"],
            locationname: self.jd["sample_to_samplelocation"],
            locationpath: self.jd["sample_to_samplelocation"],
            type: self.jd["sample_to_sampletype"],
            stockprocessing: self.jd["sample_to_stockprocessing"],
            secondprocessing: self.jd["sample_to_secondprocessing"],
            project: self.jd["sample_to_project"],
            receptacle: self.jd["sample_to_receptacle"],
            orga: self.jd["sample_to_orga"],
            trial: self.jd["sample_to_trial"]
        }
``

for any patient idc, join in patientcontainer, which is needed by
_append_idc_joins.

``
        for pidc in self._patientidcs(pidc):
            joins[pidc] = self.jd["sample_to_patient"]
``

put together the select string and join string for the query.

`` #py
        selectstr = self._selectstr(jselects, verbose, lselects, idc)  
        joinstr = self._joinstr(joins, verbose, idc, pidc=pidc)  
``

get the where string.

`` #py
        (wherestr, whereargs) = self._where(lists, tmptables, idc, idctmptables, like=like)
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query, get the result and return it.

`` #py
        query = f"select {topstr} {selectstr} from centraxx_sample sample \n{joinstr}"
        if wherestr.strip() != "":
            query += f"\nwhere {wherestr}"
        if order_by is not None:
            query += " " + self._order_by(order_by)
            
        if print_query:
           print(query)
           print(whereargs)

        res = self.db.qfad(query, whereargs)
``

clear the temporary tables.

``
        self._cleartt(tmptables)
        self._cleartt(idctmptables)
``

if raw is wished return the raw result.

``
        if raw:
            return res
``

the first implementation tried to take the tablenames/colums as keys
for the returned json fields, but that doesn't quite work for
patientpsn, where the key would be just 'idcontainer.psn'. so for now
joined-in fields are renamed to 'sampleid', 'patientid',
'parentid' etc. // todo still true?

turn the result to samples.

``
        sarr = []
        for r in res:
            ``.``
``

collect the sample's ids.

``
            ids = []
            #if dig(r, sampleid) is not None:
            #    ids.append(Identifier(id=dig(r, sampleid), code=self.sidc()))
            for idc in self._sampleidcs():
                #print("idc:" + idc)
                #print("r:" + str(r))
                if idc.lower() in r and r[idc.lower()] is not None:
                    ids.append( Identifier(id=dig(r, idc.lower()), code=idc.upper()) )
``

include the oid.

``
            ids.append( Identifier(id=int(dig(r, sampleoid)), code="oid") ) # todo rename sampleoid?
``

reference the parent as an Idable to be able to include both oid and
sampleid. the oid is needed for aliquotgroups that don't come with an
idcontainer.

``
            pids = []
            if r[parentoid] is not None:
                pids.append(Identifier(id=int(r[parentoid]), code="oid"))
            if dig(r, parentid) is not None:
                pids.append(Identifier(id=dig(r, parentid), code=self.sidc()))
            parent = None
            if len(pids) > 0:
                parent = Idable(ids=pids, mainidc=self.sidc())
``

also reference the patient as Idable.

``
            patids = []
            if dig(r, patientid) is not None:   # todo include patient oid?
                patids.append(Identifier(id=dig(r, patientid), code=self.pidc(pidc)))
            patient = None
            if len(patids) > 0:
                patient = Idable(ids=patids, mainidc=self.pidc(pidc))
``

build the sample.

``
            s = Sample(
                appointment=dig(r, appointment),
                category=dig(r, category),
                samplingdate=dig(r, samplingdate),
                concentration=dig(r, concentration),
                cxxkitid=dig(r, cxxkitid),
                creationdate=dig(r, creationdate),
                derivaldate=dig(r, derivaldate),
                ids=Idable(ids=ids, mainidc=self.sidc()),
                initialamount=Amount(floatornull(dig(r, initialamount)), dig(r, initialunit)), # apparently the cast to float is explicitly needed
                kitid=dig(r, kitid),
                locationpath=dig(r, locationpath),
                locationname=dig(r, locationname),
                orga=dig(r, orga),
                parent=parent,
                patient=patient,
                project=dig(r, project),
                receiptdate=dig(r, receiptdate),
                receptacle=dig(r, receptacle),
                repositiondate=dig(r, repositiondate),
                restamount=Amount(floatornull(dig(r, restamount)), dig(r, restunit)),
                secondprocessing=dig(r, secondprocessing),
                secondprocessingdate=dig(r, secondprocessingdate),
                stockprocessing=dig(r, stockprocessing),
                stockprocessingdate=dig(r, stockprocessingdate),
                trial=dig(r, trial),
                type=dig(r, type), 
                xposition=dig(r, xposition), 
                yposition=dig(r, yposition)
            )
            sarr.append(s)
``

buffer each fetch to r with dig, for keys that are not in r.

return.

``/sample
        return sarr
``

import.

``/import
from datetime import datetime
from dip import dig, dis
from tram import Sample, Idable, Amount, Identifier
``

the joindict entries that sample needs.

``/init/jd sample_to:
            "sample_to_samplekit": [f"left join centraxx_samplekititem as samplekititem on samplekititem.tubebarcode = idc_{self.sidc()}.psn", "left join centraxx_samplekit as samplekit on samplekit.oid = samplekititem.samplekit"],
            "sample_to_parentid": [f"left join centraxx_sampleidcontainer parentidc on parentidc.sample = sample.parent and parentidc.idcontainertype={self._idcoid[self.sidc()]}"],
            "sample_to_samplelocation": ["left join centraxx_samplelocation samplelocation on samplelocation.oid = sample.samplelocation"],
            "sample_to_sampletype": ["left join centraxx_sampletype as sampletype on sampletype.oid = sample.sampletype"],
            "sample_to_stockprocessing": ["left join centraxx_stockprocessing as stockprocessing on sample.stockprocessing = stockprocessing.oid"],
            "sample_to_secondprocessing": ["left join centraxx_stockprocessing as secondprocessing on sample.secondprocessing = secondprocessing.oid"],
            "sample_to_project": ["left join centraxx_project as project on sample.project = project.oid"],
            "sample_to_patient": ["left join centraxx_patientcontainer as patientcontainer on sample.patientcontainer = patientcontainer.oid"],
            "sample_to_receptacle": ["left join centraxx_samplereceptable as receptable on sample.receptable = receptable.oid"], # receptable seems to be a typo in the table naming
            "sample_to_orga": ["left join centraxx_organisationunit as organisationunit on sample.orgunit = organisationunit.oid"],
            "sample_to_trial": ["left join centraxx_flexistudy as flexistudy on sample.flexistudy = flexistudy.oid"]
``

_get_parents collects the parent sample oids of a sample in the `out`
list, in order from root to leaf. take oids to include aliquotgroups,
they don't necessarily have an idcontainer attached to them.

``/_get_parents:
    def _get_parents(self, oid, out):
        ``.``
``

get the parent oid. query directly for performance (sample() would
join in the sampleid idcontainer by default).

``
        res = self.db.qfad("select parent from centraxx_sample where oid = ?", oid)
        pid = dig(res[0], "parent")
``

insert the parent at the front of the out array, to keep the root-to-leaf
direction.

``
        if pid is not None:
            out.insert(0, pid)
            ``.``
``

recurse to get the parent's parent.

``
            self._get_parents(pid, out)
``

_get_childs collects the oids of the sample's children in the `out`
list, in order from root-to-leaf. take oids to include aliquotgroups.

``/_get_childs:
    def _get_childs(self, oid, out):
        ``.``
``

get the children. query directly for performancs (sample() would join
in the main sample idcontainer by default).

``
        res = self.db.qfad("select oid from centraxx_sample where parent = ?", oid)
``

if there are children, append them.

``
        for child in res:
            out.append(child["oid"])
``

returse to get the children of the children.

``
            self._get_childs(child["oid"], out)
``

patient gets patients and returns them as a list of Patient instances.

the parameters work analog to the sample method.

``/patient: #py
    def patient(self, patientids=None, pidc=None, sampleids=None, idc=None, trials=None, orgas:list=None, files:dict=None, verbose:list=None, verbose_all=False, like:list=None, order_by=None, top=None, print_query:bool=False, raw:bool=False):
        ``.``
``

init arrays to avoid mutable default parameters.

``
        if verbose is None:
            verbose = []
        if like is None:
            like = []
        if files is None:
            files = {}
        if idc is None:
            idc = {}
``

vaa (verbose-all-array) holds all possible verbose options for patient.

`` #py
        vaa = [orga]
``

append the idcs for patient to the vaa array.  don't append idcs for
sample, cause then one patient with fifteen samples would come out as
fifteen result rows?

``
        vaa.extend(self._patientidcs(pidc))        
``


always join the patientid via verbose. put it as the first array element
for subsequent joins that might need it.

`` #py
        if not self.pidc(pidc) in verbose:
            verbose.insert(0, self.pidc(pidc))
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        files = self._concrete_idcs_dict(files, pidc=pidc)
``

put the arguments in a dict of lists.

``
        lists = {
          trial: trials,
          orga: orgas
        }
``

resolve the sampleid and patientid shortcut by putting their lists
into the idc dict.

``
        _dextend(idc, self.sidc(), sampleids)
        _dextend(idc, self.pidc(pidc), patientids)
``

now idc holds all parameters queryable as idcontainers.

put files and all lists larger than 100 items into temporary
tables.

``
        (tmptables, idctmptables) = self._makemove(files, lists, idc, 100, pidc=pidc)
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
``

put the keys for the arguments into the verbose array.

``
        if orgas is not None:
            verbose.append(orga)
``

make an array of silent joins for fields that might get queried after
but shouldn't be included in the output.

`` #py
        silent = []
        if trials:
            silent.append(trial)
        if orgas:
            silent.append(orga)
``


make sure that the verbose array only contains keys from the
verbose-all-array.

// what about?
add the sampleid extra cause it strictly isn't allowed as a verbose
flag, but if verbose is used to orchestrate all joins it needs to be
in verbose for idc?

``
        if not _checkverbose(verbose, vaa):
            return None # throw error?
``

the select statements for optional joins by key.

`` #py
        selects = {
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],
            orga: [f"organisationunit.code as '{orga}'"],
            trial: [f"flexistudy.code as '{trial}'"],
        }
``

the join statements for optional joins by key. if the same join is
needed for two different keys they are filtered out later.

pull the values from the join dict, jd.

`` #py
        joins = {
            orga: self.jd["patient_to_orga"],
            trial: self.jd["patient_to_trial"]
        }
``

for any sample idc, join in sample, which is needed by
_append_idc_joins.

``
        for sidc in self._sampleidcs():
            joins[sidc] = self.jd["patient_to_sample"]
``

put together the select string for the query. always select
patientcontainer.

`` #py
        selectstr = self._selectstr(selects, verbose, ["patientcontainer.*"], idc)  
``

put together the join string for the query. join in verbose and
silent.

``
        joinstr = self._joinstr(joins, verbose + silent, idc, pidc=pidc)  
``

get the where string.

`` #py
        (wherestr, whereargs) = self._where(lists, tmptables, idc, idctmptables, like=like)
        #print(whereargs)
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query. select distinct so that sample joins for
idcontainers etc don't result in a patient getting returned multiple
times if there's multiple samples.


`` #py
        query = f"select distinct {topstr} {selectstr} from centraxx_patientcontainer patientcontainer \n{joinstr} \nwhere {wherestr}"
        if order_by is not None:
            query += " " + self._order_by(order_by)
        if print_query:
           print(query)
``

get the result.

``
        res = self.db.qfad(query, whereargs)
``

remove the temporary tables.

``
        self._cleartt(tmptables)
        self._cleartt(idctmptables)        
``

if raw is wished, return raw.

``
        if raw:
            return res
``

make patients from the result.

``
        pats = []
        for r in res:
            ``.``
``

collect the ids.

``
            ids = [ Identifier(id=dig(r, patientid), code=self.pidc(pidc)) ]
            for idc in self._patientidcs(pidc):
                if idc in r and r[idc] is not None:
                    ids.append( Identifier(id=dig(r, idc), code=idc.upper()) )
``

build the patient.

``
            pat = Patient(
              ids=Idable(ids=ids, mainidc=self.pidc(pidc)),
              orga=dig(r, orga)
            )
            pats.append(pat)
            #print("pat: " + str(pat))
``

return.

``/patient
        return pats
``

import.

``/import
from tram import Patient
``


the joindict entries that patient needs.

``/init/jd patient_to:
            "patient_to_orga": ["left join centraxx_patientorgunit patientorgunit on patientcontainer.oid=patientorgunit.patientcontainer_oid", "left join centraxx_organisationunit organisationunit on patientorgunit.orgunit_oid=organisationunit.oid"],
            "patient_to_trial": ["left join centraxx_patientstudy as patientstudy on patientstudy.patientcontainer = patientcontainer.oid", "left join centraxx_flexistudy as flexistudy on flexistudy.oid = patientstudy.flexistudy"],
            "patient_to_sample": ["left join centraxx_sample sample on sample.patientcontainer = patientcontainer.oid"]
``


trial gives trials.

``/trial: #py
    def trial(self):
        ``.``
``

return the trial codes for now.

``
        query = "select code from centraxx_flexistudy"
        res = self.db.qfad(query)
        return res
``

finding gets the laborfindings ("messbefund" / "begleitschein") for
sampleids or method.  it returns a list of Finding instances.

you can pass these to verbose: tr.patientid  // maybe also tr.values?

``/finding: #py
    def finding(self, sampleids=None, patientids=None, pidc:str=None, idc=None, methods=None, trials=None, values:bool=True, verbose:list=None, files:dict=None, verbose_all:bool=False, names:bool=False, top:int=None, print_query:bool=False, raw:bool=False):
        ``init``
        ``findings``
        ``values``
        ``ret``
``

init arrays to avoid multiple default parameters.

``/finding/init:
        if verbose is None:
            verbose = []
        if files is None:
            files = {}
        if idc is None:
            idc = {}
``

vaa (verbose-all-array) holds all possible verbose options for patient.

``/finding/findings: #py
        vaa = [patientid] # include trial?
``

on verbose_all include all constants in the verbose array.

`` #py
        if verbose_all == True:
            verbose = vaa
``

put the keys for the arguments into the verbose array.

``
        if trials is not None:
            verbose.append(trial)
``

for now always include the sampleid.

``
        if self.sidc() not in verbose:
            verbose.append(self.sidc())
``

replace traction constants patientid and sampleid with their idc.

``
        verbose = self._concrete_idcs(verbose, pidc=pidc)
        files = self._concrete_idcs_dict(files, pidc=pidc)
``

put the arguments in a dict of lists.

``
        lists = {
          method: methods,
          trial: trials
        }
``

resolve the sampleid and patientid shortcut by putting their lists
into the idc dict.

``
        _dextend(idc, self.sidc(), sampleids)
        _dextend(idc, self.pidc(pidc), patientids)
``

now idc holds all parameters queryable as idcontainers.

put files and all lists larger than 100 items into temporary
tables.

``
        (tmptables, idctmptables) = self._makemove(files, lists, idc, 100, pidc=pidc)
``

build the query for findings.  later add recorded values to each finding.

get the idc part of the select string.

``
        selects = {
            self.sidc(): [f"idc_{self.sidc()}.psn as '{sampleid}'"],
            self.pidc(pidc): [f"idc_{self.pidc(pidc)}.psn as '{patientid}'"],                   
        }
        idcselectstr = self._selectstr(selects, verbose, [], idc)  
``

for any patient idc, join in patientcontainer, which is needed by
_append_idc_joins.

``
        joins = {
            trial: self.jd["sample_to_trial"]
        }
        for pidc in self._patientidcs(pidc):
            joins[pidc] = self.jd["sample_to_patient"]
``

get the join string for idcs.

``
        idcjoinstr = self._joinstr(joins, verbose, idc, pidc=pidc)
``

get the top string.

``
        topstr = self._top(top)
``

stick together the query.

``
        query = f"""select {topstr} laborfinding.oid as "laborfinding_oid", laborfinding.*, labormethod.code as {method}, {idcselectstr}
        from centraxx_laborfinding as laborfinding

        -- go from laborfinding to sample
        left join centraxx_labormethod as labormethod on laborfinding.labormethod = labormethod.oid
        left join centraxx_labormapping as labormapping on labormapping.laborfinding = laborfinding.oid
        left join centraxx_sample sample on labormapping.relatedoid = sample.oid
        {idcjoinstr}"""
``

get the where string and append it to the query.

``
        (wherestr, whereargs) = self._where(lists, tmptables, idc, idctmptables)        

        query += " where " + wherestr
        if print_query:
            print(query)
            print(whereargs)
``

get the result.

``
        results = self.db.qfad(query, whereargs)
``

remove the temporary tables holding bcp data.

``
        self._cleartt(tmptables)
        self._cleartt(idctmptables)        
``

for each of the findings, pull in the recorded values.

maybe only on --verbose = ["values"]

if names should be loaded, get the laborvalue display names. load them
once to avoid joining them in each time, is that quicker?

catalogentry and usageentry display names are loaded in _make_rec if
needed.

``/finding/values:
        if names is True:
            self.names_laborvalue = self.name(table="laborvalue")
``

now iterate the findings and get their recorded values.

``
        for i, finding in enumerate(results):
            if values != True: # todo put this outside of the loop?
                continue
            ``query``
            ``put``
``

construct the query for the recorded values.

todo prefetch units?

``/finding/values/query:
            query = f"""select recordedvalue.*, laborvalue.code as laborvalue_code, laborvalue.dtype as laborvalue_type, laborvalue.custom_catalog as laborvalue_catalog_oid, unit.code as laborvalue_unit
                from centraxx_laborfinding as laborfinding

                -- go from laborfinding to recorded value
                join centraxx_labfindinglabval as labfindinglabval on labfindinglabval.laborfinding = laborfinding.oid
                join centraxx_recordedvalue as recordedvalue on labfindinglabval.oid = recordedvalue.oid

                --go from labfindinglabval to the laborvalue for the messparam
                join centraxx_laborvalue laborvalue on labfindinglabval.laborvalue = laborvalue.oid

                --go from laborvalue to unit
                left join centraxx_unity unit on laborvalue.unit = unit.oid

                where laborfinding.oid = ?
            """
``

turn the result into recorded value objects. key the values by
laborvalue_code (the messparam code).

``
            recvals = self.db.qfad(query, finding['laborfinding_oid'])
            valsbycode = {}
            for recval in recvals:
              valsbycode[recval["laborvalue_code"]] = self._make_rec(recval, finding, names)
``

put the values to the finding.

``/finding/values/put:
            results[i]["values"] = valsbycode
``

if raw, return.

``/finding/ret:
        if raw:
            return results
``

make findings from the results.

``
        findings = []
        for res in results:
            finding = Finding(
                findingdate=dig(res, "findingdate"),
                method=res["method"],
                methodname=res["shortname"],
                patient=Idable(id=dig(res, patientid), code=self.pidc(pidc), mainidc=self.pidc(pidc)) if dig(res, patientid) is not None else None, 
                recs=res["values"] if "values" in res else None, # todo None ok?
                sample=Idable(id=res[sampleid], code=self.sidc(), mainidc=self.sidc()),
                sender=None
            )
            findings.append(finding)
``                     

return the findings with their respective values.

``/finding/ret
        return findings
``

import.

``/import
from tram import Finding
from tram import Rec, BooleanRec, NumberRec, StringRec, DateRec, MultiRec, CatalogRec
``

_make_rec makes a recorded value instance for finding from db results with display names if wished.

``/_make_rec:
    def _make_rec(self, recval, finding, names:bool=False) -> Rec:
        ``.``
``

make different rec val instances depending on the type. see the Rec
type attribute for an overview of the different types.

convert the boolean values from integer to boolean.

``
        out:Rec = None
        if recval["laborvalue_type"] == "BOOLEAN":
            val = True if recval["boolvalue"] == 1 else False
            out = BooleanRec(method=finding["method"], labval=recval["laborvalue_code"], rec=val)
``

take DECIMAL values from the numericvalue field.

somehow the cast to float seems necessary, if the Decimal from the db
result is passed, the value ends up being None.

if a number value isn't set, the db returns None (and not 0.0 or so).

``
        elif recval["laborvalue_type"] == "DECIMAL":
            #print(recval["laborvalue_code"])
            #print(recval)
            value = float(recval["numericvalue"]) if recval["numericvalue"] is not None else None
            out = NumberRec(method=finding["method"], labval=recval["laborvalue_code"], rec=value, unit=recval["laborvalue_unit"])
``

there are only four laborvalues for INTEGER, and they don't seem to be
findable with erweiterte suche. TODO what to do?

handle both STRING and LONGSTRING as StringRec.

``
        elif recval["laborvalue_type"] == "STRING" or recval["laborvalue_type"] == "LONGSTRING":
            out = StringRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["stringvalue"])
``

take DATE values from datevalue and LONGDATE values from
datevalueprecision, respectively.

``
        elif recval["laborvalue_type"] == "DATE":
            out = DateRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["datevalue"])
        elif recval["laborvalue_type"] == "LONGDATE":
            out = DateRec(method=finding["method"], labval=recval["laborvalue_code"], rec=recval["datevalueprecision"])
``

for catalog, query the actual catalog entries. go from recordedvalue
to catalogentry via the recordedval_catentry table.

``
        elif recval["laborvalue_type"] == "CATALOG":
            # get the catalog code
            query = f"""select catalog.code as 'catalog_code' from centraxx_catalog as catalog
            where catalog.oid = ?""" # do this once for all catalogs on startup or finding() call?
            res = self.db.qfad(query, recval['laborvalue_catalog_oid'])
            catalog_code = res[0]["catalog_code"]
            # get the catalog entries
            query = f"""select catalogentry.code as 'catalogentry_code' from centraxx_recordedvalue as recordedvalue
            join centraxx_recordedval_catentry as recordedval_catentry on recordedval_catentry.recordedvalue_oid = recordedvalue.oid
            join centraxx_catalogentry as catalogentry on catalogentry.oid = recordedval_catentry.catalogentry_oid
            where recordedvalue.oid = ?"""
            res = self.db.qfad(query, recval['oid'])
            # get the catalogentry names if they are not already loaded, and cache them. maybe it's faster to load the whole names map once instead of joining them in each time?
            if names is True and self.names_catalogentry is None:
                self.names_catalogentry = self.name(table="catalogentry")
            entries = []
            value_name = {}
            for r in res:
                code = r["catalogentry_code"]
                entries.append(code)
                if names is True:
                    value_name[code] = self.names_catalogentry[code]
            
            out = CatalogRec(method=finding["method"], labval=recval["laborvalue_code"], catalog=catalog_code, rec=entries, rec_name=value_name)
``

for enumeration and option group, query the actual usage entries. go from recordedvalue
to usageentry via the recordedval_usageentry table.

for now, use a MultiRec type, that is the same as CatalogRec type,
except without catalog code?

``
        elif recval["laborvalue_type"] == "ENUMERATION" or recval["laborvalue_type"] == "OPTIONGROUP":
            query = f"""select usageentry.code as 'usageentry_code' from centraxx_recordedvalue as recordedvalue
            join centraxx_recordedval_usagentry as recordedval_usagentry on recordedval_usagentry.recordedvalue_oid = recordedvalue.oid
            join centraxx_usageentry as usageentry on usageentry.oid = recordedval_usagentry.usageentry_oid
            where recordedvalue.oid = ?"""            
            res = self.db.qfad(query, recval['oid'])

            # get the usageentry names if they are not already loaded, and cache them. maybe it's faster to load the whole names map once instead of joining them in each time?
            if names is True and self.names_usageentry is None:
                self.names_usageentry = self.name(table="usageentry")

            entries = []
            value_name = {}
            for r in res:
                code = r["usageentry_code"]
                entries.append(code)
                if names is True:
                    value_name[code] = self.names_usageentry[code]
            
            out = MultiRec(method=finding["method"], labval=recval["laborvalue_code"], rec=entries, rec_name=value_name)
``

else throw an exception.

``
        else:
            raise Exception(f"no record class for laborvalue of type {recval['laborvalue_type']}")
``

return.

``
        return out
``

method (messprofil) gets method(s) and their labvals (messparameter).
        
``/method:
    def method(self, methods=None, files:dict=None):
        ``.``
``

init files.

``
        if files is None:
            files = {}
``

put the arguments in a dict of lists.

``
        lists = {
          method: methods,
          trial: trials
        }
``

now idc holds all parameters queryable as idcontainers.

put files and all lists larger than 100 items into temporary
tables.

``
        (tmptables, idctmptables) = self._makemove(files, lists, {}, 100)
``
the query.

``
        query = f"""select laborvalue.code as labval, labormethod.code as "method"
from centraxx_labormethod labormethod
inner join centraxx_crftemplate crf_t
    on labormethod.crf_template=crf_t.oid
inner join centraxx_crftempsection crf_ts
    on crf_t.oid=crf_ts.crftemplate
inner join centraxx_crftempsection_fields crf_tsf
    on crf_ts.oid=crf_tsf.crftempsection_oid
inner join centraxx_crftempfield crf_tf
    on crf_tsf.crftempfield_oid=crf_tf.oid
inner join centraxx_laborvalue laborvalue
    on crf_tf.laborvalue=laborvalue.oid"""
``

add the where string.

``
        (wherestr, whereargs) = self._where(lists, tmptables, idc, idctmptables)

        if wherestr:
          query += " where " + wherestr
        # print(query)
``

return the result.

``
        res = self.db.qfad(query, whereargs)
``

remove the temporary tables.

``
        self._cleartt(tmptables)
        self._cleartt(idctmptables)        
``

if raw, return result as is.

`
        if raw:
            return res
`

get the names.  todo cache?

``
        methodnames = self.name(table="labormethod")
        labvalnames = self.name(table="laborvalue")
``

key the labvals by method code, add the names.

todo why are some labvals returned more than one in the query?

``
        out = {}
        for row in res:
            ``.``
``

add the method.

``
            methodcode = row["method"]
            if methodcode not in out:
                out[methodcode] = {}
                out[methodcode]["code"] = methodcode
                out[methodcode]["name_de"] = dig(methodnames, methodcode + "/de")
                out[methodcode]["name_en"] = dig(methodnames, methodcode + "/en")
                out[methodcode]["labvals"] = {}
``

add labvals to method.

``
            labvalcode = row["labval"]

            labval = {}
            labval["code"] = labvalcode
            labval["name_de"] = dig(labvalnames, labvalcode + "/de")
            labval["name_en"] = dig(labvalnames, labvalcode + "/en")            
            out[methodcode]["labvals"][labvalcode] = labval
``

return.

``
        return out
``


``/user:
    def user(self, usernames:list=None, emails:list=None, lastlogin=None, files:dict=None, verbose:list=None):
        ``.``
``

init arrays to avoid multiple default parameters.

``
        if verbose is None:
            verbose = []
        if files is None:
            files = {}
``
        

verbose all array holds the possible verbose options.

``
        vaa = [tr.address, tr.login]
``

put the keys for the given arguments into the verbose array for joining them in.

tr.address and tr.login are catch-alls for address and login related fields.

``
        if usernames:
            verbose.append(tr.username)
        if emails:
            verbose.append(tr.address)
        if lastlogin:
            verbose.append(tr.login)
``

put the arguments in a dict of lists.

``
        lists = {
          username: usernames,
          address: emails,
          login: lastlogin
        }
``

now idc holds all parameters queryable as idcontainers.

put files and all lists larger than 100 items into temporary
tables.

``
        (tmptables, idctmptables) = self._makemove(files, lists, idc, 100)
``

todo wherestring and build query?

remove the temporary tables holding bcp data.

``
        self._cleartt(tmptables)
        self._cleartt(idctmptables)        
``

turn the result into user instances.

``
        out = []
        for r in res:
            user = User(
                email=dig(r, tr.email),
                lastlogin=dig(r, tr.lastlogin),
                username=dig(r, tr.username),
            )
            out.append(user)
``

return.

``
        return out
``

the join dict entries for user.

``/init/jd participant_to:
            "participant_to_address": ["left join centraxx_participantaddress participantaddress on participantaddress.participant = participant.oid", "left join centraxx_address address on address.oid = participantaddress.oid"],
            "participant_to_credential": ["left join centraxx_credential credential on credential.participant = participant.oid"]
``

catalogentry gives the catalogentries per catalog.

``/catalogentry:
    def catalogentry(self):
        ``.``
``

query the catalogentries, joining in their cataloges.

``
        query = """select catalogentry.code as 'entry_code', catalog.code as 'catalog_code' from centraxx_catalogentry catalogentry
join centraxx_catalog catalog on catalogentry.catalog = catalog.oid"""
        res = self.db.qfad(query)
``

get the names for catalog entries and cataloges.

``
        catnames = self.name(table="catalog")
        entrynames = self.name(table="catalogentry")
``

put the output together. key by catalog code. add the display names.

``
        out = {}
        for row in res:
            entrycode = dig(row, "entry_code")
            catcode = dig(row, "catalog_code")
            # create the catalog
            if not catcode in out:
                out[catcode] = {}
                out[catcode]["code"] = catcode
                out[catcode]["name_de"] = dig(catnames, catcode + "/de")
                out[catcode]["name_en"] = dig(catnames, catcode + "/en")
                out[catcode]["entries"] = {}
            # add the entry
            entry = {}
            entry["code"] = entrycode
            entry["name_de"] = dig(entrynames, entrycode + "/de")
            entry["name_en"] = dig(entrynames, entrycode + "/en")        
            out[catcode]["entries"][entrycode] = entry
``

return.

``
        return out
``

usageentry gives the usageentries.

``/usageentry:
    def usageentry(self):
        ``.``
``

get the usageentries.

``
        query = "select code from centraxx_usageentry"
        res = self.db.qfad(query)
``

get the display names (todo cache)?

``
        names = self.name(table="usageentry")
``

put the names to the codes.

``
        out = {}
        for row in res:
            code = row["code"]
            out[code] = {}
            out[code]["name_de"] = dig(names, code + "/de")
            out[code]["name_en"] = dig(names, code + "/en")
            out[code]["code"] = code
``

return.

``
        return out
``

name gives the multilingual names for a code or all codes in a table.

the result is keyed by code and language like this:


"NUM_NMR_ISOLEUCINE_VALUE": {  
   "de": "Isoleucin",  
   "en": "Isoleucine"  
}


table: the name of the centraxx table without centraxx_ prefix  
code: a specific code, if none given, all code - name mappings for table are given  
lang: de|en  
ml_table: if the name of the table connecting to multilingualentry is not simlpy the queried table name followed by "_ml_name", give the connecting table's name here. eg: name('laborvaluegroup', ..., ml_name='labval_grp_ml_name')  


``/name:
    def name(self, table:str, code:str=None, lang:str=None, ml_table:str=None):
        ``.``
``

interlacing the table name assumes that the referencing pattern for
multilingual entries stays the same across table names.

``
        query = "select [" + table + "].code, multilingual.value as name, multilingual.lang as lang"
        query += " from [centraxx_" + table + "] as [" + table + "]"
``

put together the name for the ml_table.

``
        ml_name = ""
        if ml_table != None: # the name is different
            ml_name = "centraxx_" + ml_table
        else: # the name is the same
            ml_name = "centraxx_" + table + "_ml_name"
``

add it to the query.

``
        query += " inner join [" + ml_name + "] mlname on mlname.related_oid = [" + table + "].oid"
        query += " inner join centraxx_multilingualentry multilingual on mlname.oid = multilingual.oid"
``

restrict the query to specific lang or code if given.

``
        wherestrings = []
        args = []
        if code != None:
            wherestrings.append(self._whereparam("[" + table + "].code"))
            args.append(code)
        if lang != None:
            wherestrings.append(self._whereparam("multilingual.lang"))
            args.append(lang)
``

only add sql-where if needed.

``
        if len(wherestrings) > 0:
            query += " where "
            # join where clauses by and
            query += " and ".join(wherestrings)

        # print(query)
``

query.

``
        res = self.db.qfad(query, *args)
``

structure by code and lang and return.

``
        out = {}
        for line in res:
            code = line["code"]
            lang = line["lang"]
            if not code in out:
               out[code] = {}
            out[code][lang] = line["name"]
        return out
``

sidc returns the main idc code by which samples are referenced as
specified in the settings. 

``/sidc:
    def sidc(self) -> str:
        return self.settings['sampleid'][self.db.target]
``

sidc returns the main idc code by which patients are referenced as
specified in the settings. if a pidc argument is given, it is returned
instead of the settings' pidc.

``/pidc:
    def pidc(self, pidc:str=None) -> str:
        if pidc is not None:
            return pidc
        return self.settings['patientid'][self.db.target]
``

_sampleidcs returns the idcs from settings that are specific for sample.

rather make this a section in conf?

# idc holds idcontainer codes that should be queryable as command line flags 
idc:
  sample:
    - extsampleid
    - modul
    - tier
  patient:
    - mpi

``/_sampleidcs:
    def _sampleidcs(self) -> list:
        ``.``
``

the settings can list idc codes that are not applicable to this
target, skip them.

``
        out = []
        for idc in self.settings["idc"]:
            if idc in self._idckind and self._idckind[idc] == "SAMPLE":
                out.append(idc)
        # include the main sample idcontainer
        out.append(self.sidc())
        return out
``

patientidcs returns the idcs from settings that are specific for
sample.

``/_patientidcs:
    def _patientidcs(self, pidc:str=None) -> list:
        ``.``
``

the settings can list idc codes that are not applicable to this target, skip them.

``
        out = []
        for idc in self.settings["idc"]:
            if idc in self._idckind and self._idckind[idc] == "PATIENT":
                out.append(idc)
        # include the main patient idcontainer
        out.append(self.pidc(pidc))
        return out
``

_concrete_idcs replaces traction constants patientid and sampleid with their
respective idc for array.

``/_concrete_idcs:
    def _concrete_idcs(self, verbose, pidc=None):
        ``.``
``

fill in the concrete idcs when encountering patientid or sampleid.

``
        out = []
        for verb in verbose:
            if verb == patientid:
                out.append(self.pidc(pidc))
            elif verb == sampleid:
                out.append(self.sidc())
            else:
                out.append(verb)
        return out
``

_concrete_idcs_dict replaces traction constants patientid and sampleid with their
respective idc for dict.

``/_concrete_idcs_dict:
    def _concrete_idcs_dict(self, d, pidc=None):
        ``.``
``

fill in the concrete idcs when encountering patientid or sampleid.

``
        out = {}
        for key, val in d.items():
            #print("key: " + key)
            if key == patientid:
                out[self.pidc(pidc)] = val
            elif key == sampleid:
                #print("here: " + self.sidc())
                out[self.sidc()] = val
            else:
                out[key] = val
        return out
``

_fill_in_primary adds a reference to the given sample's primary sample,
if there is one.

``/_fill_in_primary:
    def _fill_in_primary(self, sample:Sample):
        ``.``
``

get the parent oids. 

``
        poids = []
        self._get_parents(sample.id("oid"), poids)
``

the first parent is the primary, take it.

``
        if len(poids) > 0:
            primary_oid = poids[0]
            ``.``
``

query the primary to get its sampleid, reference it from the sample as
Idable.

``
            primary = self.sample(oids=[primary_oid])[0]
            sample.primary = Idable(ids=primary.ids, mainidc=primary.mainidc)
``

_selectstr filters the selects by the verbose array and returns the
sql select string. selecta is for fields that should be selected
regardless if they're in the verbose array or not.

the idc argument assumes that the sample table is joined it. // todo is this still true?

``/_selectstr: #py
    def _selectstr(self, selects, verbose, selecta, idc):
        for verb in verbose:
            ``.``        
``

skip verbose entries that are not in the selects dict, they are
probably idc selects that are handled later.

``
            if not verb in selects:
                continue
``

put in the select line(s).

``
            for s in selects[verb]:
                selecta.append(s)
``

append idc selects.

``/_selectstr #py
        selecta = self._append_idc_select(selecta, idc, verbose)
``      

get the selections and joins as string.

`` #py
        selectstr = ", \n".join(selecta)
        return selectstr
``

_joinstr puts together the joins needed by verbose array and idc keys
and returns the sql join string.

``/_joinstr: #py
    def _joinstr(self, joins, verbose, idc, pidc=None):
        ``.``
``

first put in the idc joins, cause other joins might need them.

``
        joina = []
        joina = self._append_idc_join(joina, idc, verbose, joins, pidc=pidc)
``

now put in joins for verbose.

could you substract idc from verbose here cause there were already taken care of?

``
        for verb in verbose: 
            ``.``
``


skip verbose entries that are not in the joins dict, //they are 
probably idc joins that are handled later. ?true?

``
            if not verb in joins:
                continue
``

put in the join line(s). make sure that join clauses aren't included
double, for example both locationpath and locationname join in
samplelocation, so check that it's not already in the join array.

``
            for s in joins[verb]:
                if not s in joina:
                    joina.append(s)
``


get the joins as string.

`` #py
        joinstr = " \n".join(joina)
        return joinstr
``

_append_idc_select adds the sql select statements for an idc dict.

``/_append_idc_select:
    def _append_idc_select(self, selecta, idc, verbose):
        ``.``
``

put in the members of verbose touched by idc.

``
  idca = []
  for verb in verbose:
    if verb in self.settings["idc"]:
      idca.append(verb)
``    

make select strings and append them.

``
  for item in idca:
    selectstr = f"idc_{item}.psn as '{item}'"
    if not selectstr in selecta:
      selecta.append(selectstr)
``

return the selecta with appended strings.

``
  return selecta
``

_append_idc_join adds the sql join statements for an idc dict.

``/_append_idc_join: #py
    def _append_idc_join(self, joina, idc, verbose, joins, pidc=None):
        ``.``
``

put in the members of verbose touched by idc and the keys of idc into
a common array.

``
        idca = []
        for verb in verbose:
          if verb in self.settings["idc"] or verb == self.sidc() or verb == self.pidc(pidc):
            idca.append(verb)
        if idc is not None:
          idca.extend(idc.keys())
``

add a join for each member of the idc array.

the joins are different for idckind SAMPLE and PATIENT.

``
        for item in idca:
          ``intermediary``
          if self._idckind[item] == "SAMPLE":
            ``sample``
          elif self._idckind[item] == "PATIENT":
            ``patient``
          else:
            print(f"error: idcontainer kind {self._idckind[item]} not supported.")
``

put in idc-intermediary joins, for when sample joins in patient idcs and
needs patientcontainer for that or vice versa. 

``./intermediary:
          if item in joins:
            for s in joins[item]:
              if s not in joina:
                joina.append(s)
``


join in sampleidcontainer for SAMPLE. prefix it with idc_ instead of
sidc_, so that there can be one where-check that uses the idc_ prefix
for both patient and sample idcontainers.

when joining in idcontainers, we need to check their respective
idcontainer type. do this here as opposed to the where clause at the
end of the query, cause here if a idcontainer is not set checking here
just makes the field null in the result row, whereas checking in the
where clause it excludes the entire row.

``../sample:
        joinstr = f"left join centraxx_sampleidcontainer as idc_{item} on idc_{item}.sample = sample.oid and idc_{item}.idcontainertype = {self._idcoid[item]}"

        if not joinstr in joina:
          joina.append(joinstr)
``

join in idcontainer via patientcontainer for PATIENT:

``../patient:
        joinstr = f"left join centraxx_idcontainer as idc_{item} on idc_{item}.patientcontainer = patientcontainer.oid and idc_{item}.idcontainertype = {self._idcoid[item]}"
        if not joinstr in joina: # neccessary?
          joina.append(joinstr)
``

return the selecta with appended strings.

``/_append_idc_join
        return joina
``

_where returns the wherestring and args array for the provided
lists and temporary tables.

the user needs to make sure that whatever is used here is joined
into the query before.

the keys in lists and tmptables are assumed to be the tr constants,
e.g. tr.locationpath, the keys in idclists and idctmptables are
assumed to be idcontainers.

like holds tr constants and idcontainers for which to check likeness
instead of equality.

``/_where:
    def _where(self, lists:dict, tmptables:dict, idclists:dict, idctmptables:dict, like:list=None): # -> (str, list)
        ``.``
``

init arrays to avoid mutable default parameters.

``
        if like is None:
            like = []
``

map which tr constant point to which db table and column.

for now mark dates with type date.

``
        wheredict = { 
          trial: { "field": "flexistudy.code" },
          locationpath: { "field": "samplelocation.locationpath" },
          method: { "field": "labormethod.code" },
          kitid: { "field": "samplekit.kitid" },
          cxxkitid: { "field": "samplekit.cxxkitid" },
          category: { "field": "sample.dtype" },
          type: { "field": "sampletype.code" },          
          orga: { "field": "organisationunit.code" },
          parentid: { "field": "parentidc.psn" },
          parentoid: { "field": "sample.parent" },
          sampleoid: { "field": "sample.oid" },          
          samplingdate: { "field": "sample.samplingdate", "type": "date" },
          receiptdate: { "field": "sample.receiptdate", "type": "date" },
          derivaldate: { "field": "sample.derivaldate", "type": "date" },
          first_repositiondate: { "field": "sample.first_repositiondate", "type": "date" },
          repositiondate: { "field": "sample.repositiondate", "type": "date" },
          stockprocessingdate: { "field": "sample.stockprocessingdate", "type": "date" },
          secondprocessingdate: { "field": "sample.secondprocessingdate", "type": "date" }
        }
``

make arrays to hold where clauses and their respective arguments.

``
        wherestrs = []
        whereargs = []
``

go over the non-idc and idc keys seperately to distinguish in the
probably rare case that an idcontainer should be named like a tr constant.

for now do dates only for lists, not tmp tables.

go over the non-idc keys.

``
        #print("lists:")
        #print(lists)
        #print("tmptables:")
        #print(tmptables)
        for key in _uniq(list(lists.keys()) + list(tmptables.keys())):
           if dig(lists, key) is not None and dig(wheredict, key + "/type") == "date":
               (wstr, wargs) = self._wheredate(dig(lists, key), wheredict[key]["field"])
           else:
               (wstr, wargs) = self._whereexact(dig(lists, key), dig(tmptables, key), wheredict[key]["field"])
           if wstr != "()":
               wherestrs.append(wstr)
               whereargs.extend(wargs)
``

go over the idc keys.

don't check for date here.

``
        for key in _uniq(list(idclists.keys()) + list(idctmptables.keys())):
            (wstr, wargs) = self._whereexact(dig(idclists, key), dig(idctmptables, key), f"idc_{key}.psn")
            if wstr != "()":
                wherestrs.append(wstr)
                whereargs.extend(wargs)
``

chain the where clauses by and.

``
        wherestr = " and ".join(wherestrs)
``

return the where string and its arguments.

``
        return (wherestr, whereargs)
``

_wheredate makes a date check. for now only check that it's between
the two values of the array passed as date parameter.

``/_wheredate:
    def _wheredate(self, tpl, dbfield): # -> (str, list)
        ``.``
``

for null checks, instead of the date tuple, 'NULL' is passed. maybe a
bit hacky?

``
        wstr = ""
        wargs = []
        if tpl == 'NULL':
            wstr = "(" + dbfield + " is NULL)"
``

check that a date is between the two dates in tpl.

CAST removes the time component, this is needed for getting samples
from one day (when both dates are the same).

ISNULL handles missing start or end date. is this smart, or rather
check for >=, <= etc if only one date is given?

``
        else:
            s = f"(CAST(" + dbfield + " as date) between ISNULL(?, " + dbfield + ") and ISNULL(?, " + dbfield + "))"
            wstr = s
            wargs.extend(tpl)
``

return where clause and args.

``
        return (wstr, wargs)
``


_whereexact returns a where clause and argument list for exact
matching of items in list and temporary table. NULL string is list is
treated as sql NULL value.

``/_whereexact:
    def _whereexact(self, lst, tmptable, dbfield:str): # -> (str, list)
        ``.``
``

open the where string.

``
        wherearg = []
        wherestr = "("
``

make null checks extra, e.g. '(kitid is NULL or kitid in (1, 2, 3))'.

if is there a 'NULL' in the array, put in a NULL check and remove it
from the array, so it doesn't mess with the where-arguments later.

``
        needsor = False
        if lst is not None and 'NULL' in lst:
            lst.remove("NULL")
            wherestr += dbfield + " is NULL"
            needsor = True
``

make the in-list part of the wherestring with the ?-placeholder
string.

``
        if lst is not None and len(lst) > 0:
            if needsor:
                wherestr += " or "
            placeholder = traction._sqlinplaceholder(len(lst)) # todo put in package? tr._sqlinplaceholder
            wherestr += dbfield + " in " + placeholder # e.g. samplelocation.locationpath in (?, ?, ?)
            wherearg.extend(lst)
            # if something comes next, chain it with or
            needsor = True
``

check against the temporary table

``
        if tmptable is not None:
            if needsor:
                wherestr += " or "
            wherestr += dbfield + " in "
            wherestr += f"(select stdin from {tmptable})"
``


close the where string, return with the arg list.

``
        wherestr += ")"
        return (wherestr, wherearg)
``


_sqlinplaceholder returns a string like (?, ?, ?, ? ...) with n question marks for sql in.

``/_sqlinplaceholder:
    def _sqlinplaceholder(n):

        # put this in a package sqlutil?

        out = "("
        for i in range(n):
            out += "?"
            if i < n - 1:
                out += ","
        out += ")"
        return out
``

_whereparam gives a ?-parameterized sql where expression for name
equal or like parameter for use in queries.

``/_whereparam:
    def _whereparam(self, name, like:bool=None):
        if like == None or like == False:
            return name + " = ?"
        else:
            return name + " like '%' + ? + '%'"
``

_wherelike gives a ?-parameterized sql where like expression.

``/_wherelike:
    def _wherelike(self, name):
        return name + " like '%' + ? + '%'"

``

_wherelikes gives a ?-parameterized sql of or-joined where-like
expressions, as many as given n.

``/_wherelikes:
    def _wherelikes(self, field, n):
        a = []
        for i in range(n):
            a.append(field + " like '%' + ? + '%'") # the sql takes literal plusses like here
        return " or ".join(a)
``

_top returns an injection-safe top string, for, e.g. `select top 100 * from table`, if
top is None return an empty string.

``/_top:
    def _top(self, top):
        ``.``
``

exit if the top param isn't a number. better use a sql building library for that?

``
        if top is not None:
           if not isnumber(top):
               raise Exception(f"top param {top} needs to be a number")
           return f"top {top}"
        return ""
``

_order_by returns an injection safe order by string.

``/_order_by:
    def _order_by(self, order_by):
        ``.``
``

exit if the order by parameter isn't an identifier.

``
        if not isidentifier(order_by):
            raise Exception(f"order_by param {order_by} needs to be an sql identifier.")
        return f"order by {order_by}"
``

_idcinit makes a mapping of idcontainers from their code (lower-case)
to respective oid and kind, and makes a list containing all idcs
including sidc and pidc.

``/_idcinit:
    def _idcinit(self):
        ``.``
``

get the codes and oids.

``
        query = "select code, oid, kind from centraxx_idcontainertype"
        res = self.db.qfad(query)
``

return idcontainer oids and kinds keyed by their code.

``
        self._idcoid = {}
        self._idckind = {}
        for row in res:
          self._idcoid[row["code"]] = row["oid"]
          self._idckind[row["code"]] = row["kind"]
``

make a list of all idcontainers that makes sure to include sidc and pidc.

``
        self._idcs = []
        for id in self.settings['idc'] + [self.sidc(), self.pidc()]:
            if id not in self._idcs:
                self._idcs.append(id)
``


_checkverbose makes shure that only allowed keys are in the verbose array. 

``/_checkverbose:
def _checkverbose(verbose, possible):
    for verb in verbose:
        if not verb in possible: 
            print(f"error: verbose entry {verb} must be in {possible}.")
            return False
    return True
``

_cleartt drops the temporary tables tables that were created with
_maketables after the query using their data was run. it takes the
dict of filetables that was returned by _maketables.

they would be dropped automatically after the session, but in case
several queries are sent in one session, maybe it's better to drop
them after each query.

``/_cleartt:
    def _cleartt(self, tmptables:dict):
        ``.``
``

go over the tables and drop them.

``
        for key, tablename in tmptables.items():
            self.db.query(f"drop table if exists {tablename}")  # todo is kairos_spring used again after this?
``

_makemove makes temporary tables for all files and all lists (non-idc
and idc) that are larger than cutoff. moved lists are removed from
lists and idclists, respectively. it returns a tuple holding dicts of
the non-idc tables and the idc tables created.

``/_makemove:
    def _makemove(self, files:dict, lists:dict, idclists:dict, cutoff:int, pidc:str=None): # -> (dict, dict)
``

replace sampleid and patientid keys by their concrete idcontainers.

``
        files = self._concrete_idcs_dict(files, pidc=pidc)
        #print("files:")
        #print(files)
``

read the files for temporary tables and split them into non-idc and
idc.

``
        (ttlists, ttidclists) = self._readfiles(files)
``

move large argument lists into the temporary table dicts.

``
        _mvlists(lists, ttlists, cutoff)
        _mvlists(idclists, ttidclists, cutoff)
``

create the temporary tables.

``
        tmptables = self._maketables(ttlists, "tmp_")
        idctmptables = self._maketables(ttidclists, "tmp_idc_")
``

return non-idc and idc tables.

``
        return (tmptables, idctmptables) 
``

_readfiles reads the files from which tmp tables should be build into
lists.  it returns a tuple of one dict holding the non-idc lists and
one dict holding the idc lists.

``/_readfiles:
    def _readfiles(self, files):
        ``.``
``

read the files.

``
        both = {}
        for key, filepath in files.items():
            lst = []
            with open(filepath, "r") as f:
                for line in f:
                    lst.append(line.rstrip())
            both[key] = lst
``

split into non-idc and idc dicts.

``
        nonidc = {}
        idc = {}
        for key, _ in both.items():
            if key in self._idcs:
                idc[key] = both[key]
            else:
                nonidc[key] = both[key]
``

return non-idc and idc as tuple.

``
        return (nonidc, idc)
``

_maketables makes temporary tables for each key in the given dict,
inserts the list of values belonging to that key, and returns a dict
the table names by key.

``/_maketables:
    def _maketables(self, d:dict, prefix:str=""): #-> dict
        ``.``
``

make the temporary tables, insert the values and remember the table names.

``
        out = {}
        for key, lst in d.items():
            name = "#" + prefix + key
            self.db.query(f"create table {name} (stdin varchar (255) )")
            for e in lst:
                self.db.query(f"insert into {name} values (?)", e)
            out[key] = name
``

return the created table names.

``
        return out
``
                

floatornull casts to float or returns None. somehow the values passed
to Amount need float casts, and float casts don't accept None.

``/floatornull:
def floatornull(x):
    if x is None:
        return None
    return float(x)
``

get_ids returns a list of string ids from a list of Idables (Sample or
Patient).

``/get_ids:
def get_ids(idables:list, code:str=None) -> list:
    return [ x.id(code) for x in idables ]
``

isnumber returns if a string is a number to prevent sql injection.  is
this handled better by an existing library function?

``/isnumber:
def isnumber(a) -> bool:
    return re.match(r"^[0-9](.[0-9]*)?$", a)
``

isidentifier returns whether a string is a sql identifier to prevent
sql injection.  like isnumber, could this be handled better by a library?

``/isidentifier:
def isidentifier(a) -> bool:
    return re.match(r"^[A-Za-z_0-9\.]+$", a)
``

import re.

``/import
import re
``

_dextends extends an array in a dictionary at the given key with the
values in the passed list.

``/_dextend:
def _dextend(d:dict, key, l:list):
    ``.``
``

the list should hold values.

``
    if l is not None:
        if not key in d:
            d[key] = []
        d[key].extend(l)
``

_mvlists moves the lists that are longer than cutoff from dicta to
dictb, deleting them in dicta. if there is already a list in dictb
under that key, extend.

``/_mvlists:
def _mvlists(dicta:dict, dictb:dict, cutoff:int):
    ``.``
``

go over dicta, if a list is larger than cutoff, move it to dictb and
delete it from dicta.

``
    for key, lst in dicta.items():
        if lst is not None and len(lst) > cutoff:
            if key in dictb:
                dictb[key].extend(lst)
            else:
                dictb[key] = lst
            del dicta[key]
``

_uniq returns a new list containing the unique items of the list passed, preserving order.

``/_uniq:
def _uniq(lst): # -> list
    out = []
    for e in lst:
        if e not in out:
            out.append(e)
    return out
``
        
       
idable_csv writes a list of Idables to the given csv file. the given
idcontainers are included as columns. if no idcontainers are given,
all are included. if True is passed as file, the output is
printed. (todo pass sys.stdout instead?)

``/idable_csv:
def idable_csv(idables:list, outfile=None, delim:str=",", *idcs) -> str:
    ``.``
``

arg parse passes None for delim if it wasn't set, set it here.

``
    if delim is None:
        delim = ","
``

if no idables return. 

``
    if idables is None or len(idables) == 0: # todo throw error?
        #print("no idables")
        return None
``

open the file.

``
    with open(outfile, "w") as f:
        ``write``
``

make a csv dict writer.

collect the column names.

``./write:
        colnames = []
        for idable in idables:
            for col in list(idable.iddict(*idcs).keys()):
                if not col in colnames:
                    colnames.append(col)
        #print("colnames:")
        #print(colnames)
        writer = csv.DictWriter(f, fieldnames=colnames, delimiter=delim)        #bm
        writer.writeheader()
``

write a row for each idable.

``
        for idable in idables:
            d = idable.iddict(*idcs)
            writer.writerow(d)
``

return the out file.

``
    return outfile
``

import csv and sys.

``/import
import csv
import sys
``


finding_csv writes a list of Findings along their recorded values to
the given csv file, the recorded values in the same row as their
respective finding. if True is passed as file the output is printed. todo use sys.stdout instead of True.

``/finding_csv:
def finding_csv(findings:list, outfile=None, delim:str=",", delim_cmp:str=",") -> str:
    ``.``
``

arg parse passes None for delim if it wasn't set, set it here.

``
    if delim is None:
        delim = ","
    if delim_cmp is None:
        delim_cmp = ","
``


if no findings return. 

``
    if findings is None or len(findings) == 0: # todo throw error?
        print("no findings")
        return None
``

make dicts from the findings and pull in the recorded values.

collect a list of all the csv column names, so that values end up in
the right columns when writing csv.

``
    fdicts = []
    colnames = []

    for finding in findings:
        ``build fdict``
``

get the dict for the finding, delete the recs field.

``./build fdict:
        fdict = finding.__dict__.copy()
        del fdict["recs"]
``

if it's the first row, remember the finding field names for the csv
header. they should be the same for all findings.

``
        if len(colnames) == 0:
            colnames.extend(list(fdict.keys()))
``

pull in the recorded values.

``
        for code, rec in finding.recs.items():
            ``pull rec``
``

for each recorded value, make a field cmp_t_CODE holding the type and
cmp_v_CODE holding the value(s).

findings come with different recorded values, if this recorded value's
labval hasn't been encountered yet, remember it as column name.


``./pull rec:
            tkey = f"cmp_t_{rec.labval}"
            vkey = f"cmp_v_{rec.labval}"
            if tkey not in colnames:
                colnames.append(tkey)
            if vkey not in colnames:
                colnames.append(vkey)
``

go through the recorded values by type.

``
            if isinstance(rec, BooleanRec):
                fdict[tkey] = "BOOL"
                fdict[vkey] = rec.rec
``

for number.

``
            if isinstance(rec, NumberRec):
                fdict[tkey] = "NUMBER"
                fdict[vkey] = rec.rec
``

for string.

``
            if isinstance(rec, StringRec):
                fdict[tkey] = "STRING"
                fdict[vkey] = rec.rec
``

for date.

``
            if isinstance(rec, DateRec):
                fdict[tkey] = "DATE"
                fdict[vkey] = rec.rec
``

for multi and catalog rec, put all entries in it's rec list into one field.

``
            if isinstance(rec, MultiRec):
                fdict[tkey] = "MULTI"
                fdict[vkey] = delim_cmp.join(rec.rec)
            if isinstance(rec, CatalogRec):
                fdict[tkey] = "CATALOG"
                fdict[vkey] = delim_cmp.join(rec.rec)
                
``

after adding the recorded values append the finding dict.

``../
        fdicts.append(fdict)
``

after the loop open the csv file.

``/finding_csv
    with open(outfile, "w") as f:
        ``write``
``

make a csv writer. pass the field names from all findings.

``./write:
        writer = csv.DictWriter(f, fieldnames=colnames, delimiter=delim)
``

write the header.

``
        writer.writeheader()
``

write the csv rows for each finding (and its recorded values).

``
        for fdict in fdicts:
            writer.writerow(fdict)
``

return the out file.

``
    return outfile
``
